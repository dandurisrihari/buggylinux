commit 0cd665bd20f9088d363158b4ac75592af18ecf4f
Author: Paolo Bonzini <pbonzini@redhat.com>
Date:   Wed Mar 25 12:50:03 2020 -0400

    KVM: x86: cleanup kvm_inject_emulated_page_fault
    
    To reconstruct the kvm_mmu to be used for page fault injection, we
    can simply use fault->nested_page_fault.  This matches how
    fault->nested_page_fault is assigned in the first place by
    FNAME(walk_addr_generic).
    
    Signed-off-by: Paolo Bonzini <pbonzini@redhat.com>

diff --git a/arch/x86/kvm/x86.c b/arch/x86/kvm/x86.c
index 003e625367b7..2ab821f6281f 100644
--- a/arch/x86/kvm/x86.c
+++ b/arch/x86/kvm/x86.c
@@ -614,12 +614,12 @@ EXPORT_SYMBOL_GPL(kvm_inject_page_fault);
 bool kvm_inject_emulated_page_fault(struct kvm_vcpu *vcpu,
 				    struct x86_exception *fault)
 {
+	struct kvm_mmu *fault_mmu;
 	WARN_ON_ONCE(fault->vector != PF_VECTOR);
 
-	if (mmu_is_nested(vcpu) && !fault->nested_page_fault)
-		vcpu->arch.nested_mmu.inject_page_fault(vcpu, fault);
-	else
-		vcpu->arch.mmu->inject_page_fault(vcpu, fault);
+	fault_mmu = fault->nested_page_fault ? vcpu->arch.mmu :
+					       vcpu->arch.walk_mmu;
+	fault_mmu->inject_page_fault(vcpu, fault);
 
 	return fault->nested_page_fault;
 }