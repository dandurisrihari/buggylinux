{
  "hash": "4f3446bb809f20ad56cadf712e6006815ae7a8f9",
  "hash_short": "4f3446bb",
  "subject": "bpf: add generic constant blinding for use in jits",
  "body": "This work adds a generic facility for use from eBPF JIT compilers\nthat allows for further hardening of JIT generated images through\nblinding constants. In response to the original work on BPF JIT\nspraying published by Keegan McAllister [1], most BPF JITs were\nchanged to make images read-only and start at a randomized offset\nin the page, where the rest was filled with trap instructions. We\nhave this nowadays in x86, arm, arm64 and s390 JIT compilers.\nAdditionally, later work also made eBPF interpreter images read\nonly for kernels supporting DEBUG_SET_MODULE_RONX, that is, x86,\narm, arm64 and s390 archs as well currently. This is done by\ndefault for mentioned JITs when JITing is enabled. Furthermore,\nwe had a generic and configurable constant blinding facility on our\ntodo for quite some time now to further make spraying harder, and\nfirst implementation since around netconf 2016.\n\nWe found that for systems where untrusted users can load cBPF/eBPF\ncode where JIT is enabled, start offset randomization helps a bit\nto make jumps into crafted payload harder, but in case where larger\nprograms that cross page boundary are injected, we again have some\npart of the program opcodes at a page start offset. With improved\nguessing and more reliable payload injection, chances can increase\nto jump into such payload. Elena Reshetova recently wrote a test\ncase for it [2, 3]. Moreover, eBPF comes with 64 bit constants, which\ncan leave some more room for payloads. Note that for all this,\nadditional bugs in the kernel are still required to make the jump\n(and of course to guess right, to not jump into a trap) and naturally\nthe JIT must be enabled, which is disabled by default.\n\nFor helping mitigation, the general idea is to provide an option\nbpf_jit_harden that admins can tweak along with bpf_jit_enable, so\nthat for cases where JIT should be enabled for performance reasons,\nthe generated image can be further hardened with blinding constants\nfor unpriviledged users (bpf_jit_harden == 1), with trading off\nperformance for these, but not for privileged ones. We also added\nthe option of blinding for all users (bpf_jit_harden == 2), which\nis quite helpful for testing f.e. with test_bpf.ko. There are no\nfurther e.g. hardening levels of bpf_jit_harden switch intended,\nrationale is to have it dead simple to use as on/off. Since this\nfunctionality would need to be duplicated over and over for JIT\ncompilers to use, which are already complex enough, we provide a\ngeneric eBPF byte-code level based blinding implementation, which is\nthen just transparently JITed. JIT compilers need to make only a few\nchanges to integrate this facility and can be migrated one by one.\n\nThis option is for eBPF JITs and will be used in x86, arm64, s390\nwithout too much effort, and soon ppc64 JITs, thus that native eBPF\ncan be blinded as well as cBPF to eBPF migrations, so that both can\nbe covered with a single implementation. The rule for JITs is that\nbpf_jit_blind_constants() must be called from bpf_int_jit_compile(),\nand in case blinding is disabled, we follow normally with JITing the\npassed program. In case blinding is enabled and we fail during the\nprocess of blinding itself, we must return with the interpreter.\nSimilarly, in case the JITing process after the blinding failed, we\nreturn normally to the interpreter with the non-blinded code. Meaning,\ninterpreter doesn't change in any way and operates on eBPF code as\nusual. For doing this pre-JIT blinding step, we need to make use of\na helper/auxiliary register, here BPF_REG_AX. This is strictly internal\nto the JIT and not in any way part of the eBPF architecture. Just like\nin the same way as JITs internally make use of some helper registers\nwhen emitting code, only that here the helper register is one\nabstraction level higher in eBPF bytecode, but nevertheless in JIT\nphase. That helper register is needed since f.e. manually written\nprogram can issue loads to all registers of eBPF architecture.\n\nThe core concept with the additional register is: blind out all 32\nand 64 bit constants by converting BPF_K based instructions into a\nsmall sequence from K_VAL into ((RND ^ K_VAL) ^ RND). Therefore, this\nis transformed into: BPF_REG_AX := (RND ^ K_VAL), BPF_REG_AX ^= RND,\nand REG <OP> BPF_REG_AX, so actual operation on the target register\nis translated from BPF_K into BPF_X one that is operating on\nBPF_REG_AX's content. During rewriting phase when blinding, RND is\nnewly generated via prandom_u32() for each processed instruction.\n64 bit loads are split into two 32 bit loads to make translation and\npatching not too complex. Only basic thing required by JITs is to\ncall the helper bpf_jit_blind_constants()/bpf_jit_prog_release_other()\npair, and to map BPF_REG_AX into an unused register.\n\nSmall bpf_jit_disasm extract from [2] when applied to x86 JIT:\n\necho 0 > /proc/sys/net/core/bpf_jit_harden\n\n  ffffffffa034f5e9 + <x>:\n  [...]\n  39:   mov    $0xa8909090,%eax\n  3e:   mov    $0xa8909090,%eax\n  43:   mov    $0xa8ff3148,%eax\n  48:   mov    $0xa89081b4,%eax\n  4d:   mov    $0xa8900bb0,%eax\n  52:   mov    $0xa810e0c1,%eax\n  57:   mov    $0xa8908eb4,%eax\n  5c:   mov    $0xa89020b0,%eax\n  [...]\n\necho 1 > /proc/sys/net/core/bpf_jit_harden\n\n  ffffffffa034f1e5 + <x>:\n  [...]\n  39:   mov    $0xe1192563,%r10d\n  3f:   xor    $0x4989b5f3,%r10d\n  46:   mov    %r10d,%eax\n  49:   mov    $0xb8296d93,%r10d\n  4f:   xor    $0x10b9fd03,%r10d\n  56:   mov    %r10d,%eax\n  59:   mov    $0x8c381146,%r10d\n  5f:   xor    $0x24c7200e,%r10d\n  66:   mov    %r10d,%eax\n  69:   mov    $0xeb2a830e,%r10d\n  6f:   xor    $0x43ba02ba,%r10d\n  76:   mov    %r10d,%eax\n  79:   mov    $0xd9730af,%r10d\n  7f:   xor    $0xa5073b1f,%r10d\n  86:   mov    %r10d,%eax\n  89:   mov    $0x9a45662b,%r10d\n  8f:   xor    $0x325586ea,%r10d\n  96:   mov    %r10d,%eax\n  [...]\n\nAs can be seen, original constants that carry payload are hidden\nwhen enabled, actual operations are transformed from constant-based\nto register-based ones, making jumps into constants ineffective.\nAbove extract/example uses single BPF load instruction over and\nover, but of course all instructions with constants are blinded.\n\nPerformance wise, JIT with blinding performs a bit slower than just\nJIT and faster than interpreter case. This is expected, since we\nstill get all the performance benefits from JITing and in normal\nuse-cases not every single instruction needs to be blinded. Summing\nup all 296 test cases averaged over multiple runs from test_bpf.ko\nsuite, interpreter was 55% slower than JIT only and JIT with blinding\nwas 8% slower than JIT only. Since there are also some extremes in\nthe test suite, I expect for ordinary workloads that the performance\nfor the JIT with blinding case is even closer to JIT only case,\nf.e. nmap test case from suite has averaged timings in ns 29 (JIT),\n35 (+ blinding), and 151 (interpreter).\n\nBPF test suite, seccomp test suite, eBPF sample code and various\nbigger networking eBPF programs have been tested with this and were\nrunning fine. For testing purposes, I also adapted interpreter and\nredirected blinded eBPF image to interpreter and also here all tests\npass.\n\n  [1] http://mainisusuallyafunction.blogspot.com/2012/11/attacking-hardened-linux-systems-with.html\n  [2] https://github.com/01org/jit-spray-poc-for-ksp/\n  [3] http://www.openwall.com/lists/kernel-hardening/2016/05/03/5\n\nSigned-off-by: Daniel Borkmann <daniel@iogearbox.net>\nReviewed-by: Elena Reshetova <elena.reshetova@intel.com>\nAcked-by: Alexei Starovoitov <ast@kernel.org>\nSigned-off-by: David S. Miller <davem@davemloft.net>",
  "full_message": "bpf: add generic constant blinding for use in jits\n\nThis work adds a generic facility for use from eBPF JIT compilers\nthat allows for further hardening of JIT generated images through\nblinding constants. In response to the original work on BPF JIT\nspraying published by Keegan McAllister [1], most BPF JITs were\nchanged to make images read-only and start at a randomized offset\nin the page, where the rest was filled with trap instructions. We\nhave this nowadays in x86, arm, arm64 and s390 JIT compilers.\nAdditionally, later work also made eBPF interpreter images read\nonly for kernels supporting DEBUG_SET_MODULE_RONX, that is, x86,\narm, arm64 and s390 archs as well currently. This is done by\ndefault for mentioned JITs when JITing is enabled. Furthermore,\nwe had a generic and configurable constant blinding facility on our\ntodo for quite some time now to further make spraying harder, and\nfirst implementation since around netconf 2016.\n\nWe found that for systems where untrusted users can load cBPF/eBPF\ncode where JIT is enabled, start offset randomization helps a bit\nto make jumps into crafted payload harder, but in case where larger\nprograms that cross page boundary are injected, we again have some\npart of the program opcodes at a page start offset. With improved\nguessing and more reliable payload injection, chances can increase\nto jump into such payload. Elena Reshetova recently wrote a test\ncase for it [2, 3]. Moreover, eBPF comes with 64 bit constants, which\ncan leave some more room for payloads. Note that for all this,\nadditional bugs in the kernel are still required to make the jump\n(and of course to guess right, to not jump into a trap) and naturally\nthe JIT must be enabled, which is disabled by default.\n\nFor helping mitigation, the general idea is to provide an option\nbpf_jit_harden that admins can tweak along with bpf_jit_enable, so\nthat for cases where JIT should be enabled for performance reasons,\nthe generated image can be further hardened with blinding constants\nfor unpriviledged users (bpf_jit_harden == 1), with trading off\nperformance for these, but not for privileged ones. We also added\nthe option of blinding for all users (bpf_jit_harden == 2), which\nis quite helpful for testing f.e. with test_bpf.ko. There are no\nfurther e.g. hardening levels of bpf_jit_harden switch intended,\nrationale is to have it dead simple to use as on/off. Since this\nfunctionality would need to be duplicated over and over for JIT\ncompilers to use, which are already complex enough, we provide a\ngeneric eBPF byte-code level based blinding implementation, which is\nthen just transparently JITed. JIT compilers need to make only a few\nchanges to integrate this facility and can be migrated one by one.\n\nThis option is for eBPF JITs and will be used in x86, arm64, s390\nwithout too much effort, and soon ppc64 JITs, thus that native eBPF\ncan be blinded as well as cBPF to eBPF migrations, so that both can\nbe covered with a single implementation. The rule for JITs is that\nbpf_jit_blind_constants() must be called from bpf_int_jit_compile(),\nand in case blinding is disabled, we follow normally with JITing the\npassed program. In case blinding is enabled and we fail during the\nprocess of blinding itself, we must return with the interpreter.\nSimilarly, in case the JITing process after the blinding failed, we\nreturn normally to the interpreter with the non-blinded code. Meaning,\ninterpreter doesn't change in any way and operates on eBPF code as\nusual. For doing this pre-JIT blinding step, we need to make use of\na helper/auxiliary register, here BPF_REG_AX. This is strictly internal\nto the JIT and not in any way part of the eBPF architecture. Just like\nin the same way as JITs internally make use of some helper registers\nwhen emitting code, only that here the helper register is one\nabstraction level higher in eBPF bytecode, but nevertheless in JIT\nphase. That helper register is needed since f.e. manually written\nprogram can issue loads to all registers of eBPF architecture.\n\nThe core concept with the additional register is: blind out all 32\nand 64 bit constants by converting BPF_K based instructions into a\nsmall sequence from K_VAL into ((RND ^ K_VAL) ^ RND). Therefore, this\nis transformed into: BPF_REG_AX := (RND ^ K_VAL), BPF_REG_AX ^= RND,\nand REG <OP> BPF_REG_AX, so actual operation on the target register\nis translated from BPF_K into BPF_X one that is operating on\nBPF_REG_AX's content. During rewriting phase when blinding, RND is\nnewly generated via prandom_u32() for each processed instruction.\n64 bit loads are split into two 32 bit loads to make translation and\npatching not too complex. Only basic thing required by JITs is to\ncall the helper bpf_jit_blind_constants()/bpf_jit_prog_release_other()\npair, and to map BPF_REG_AX into an unused register.\n\nSmall bpf_jit_disasm extract from [2] when applied to x86 JIT:\n\necho 0 > /proc/sys/net/core/bpf_jit_harden\n\n  ffffffffa034f5e9 + <x>:\n  [...]\n  39:   mov    $0xa8909090,%eax\n  3e:   mov    $0xa8909090,%eax\n  43:   mov    $0xa8ff3148,%eax\n  48:   mov    $0xa89081b4,%eax\n  4d:   mov    $0xa8900bb0,%eax\n  52:   mov    $0xa810e0c1,%eax\n  57:   mov    $0xa8908eb4,%eax\n  5c:   mov    $0xa89020b0,%eax\n  [...]\n\necho 1 > /proc/sys/net/core/bpf_jit_harden\n\n  ffffffffa034f1e5 + <x>:\n  [...]\n  39:   mov    $0xe1192563,%r10d\n  3f:   xor    $0x4989b5f3,%r10d\n  46:   mov    %r10d,%eax\n  49:   mov    $0xb8296d93,%r10d\n  4f:   xor    $0x10b9fd03,%r10d\n  56:   mov    %r10d,%eax\n  59:   mov    $0x8c381146,%r10d\n  5f:   xor    $0x24c7200e,%r10d\n  66:   mov    %r10d,%eax\n  69:   mov    $0xeb2a830e,%r10d\n  6f:   xor    $0x43ba02ba,%r10d\n  76:   mov    %r10d,%eax\n  79:   mov    $0xd9730af,%r10d\n  7f:   xor    $0xa5073b1f,%r10d\n  86:   mov    %r10d,%eax\n  89:   mov    $0x9a45662b,%r10d\n  8f:   xor    $0x325586ea,%r10d\n  96:   mov    %r10d,%eax\n  [...]\n\nAs can be seen, original constants that carry payload are hidden\nwhen enabled, actual operations are transformed from constant-based\nto register-based ones, making jumps into constants ineffective.\nAbove extract/example uses single BPF load instruction over and\nover, but of course all instructions with constants are blinded.\n\nPerformance wise, JIT with blinding performs a bit slower than just\nJIT and faster than interpreter case. This is expected, since we\nstill get all the performance benefits from JITing and in normal\nuse-cases not every single instruction needs to be blinded. Summing\nup all 296 test cases averaged over multiple runs from test_bpf.ko\nsuite, interpreter was 55% slower than JIT only and JIT with blinding\nwas 8% slower than JIT only. Since there are also some extremes in\nthe test suite, I expect for ordinary workloads that the performance\nfor the JIT with blinding case is even closer to JIT only case,\nf.e. nmap test case from suite has averaged timings in ns 29 (JIT),\n35 (+ blinding), and 151 (interpreter).\n\nBPF test suite, seccomp test suite, eBPF sample code and various\nbigger networking eBPF programs have been tested with this and were\nrunning fine. For testing purposes, I also adapted interpreter and\nredirected blinded eBPF image to interpreter and also here all tests\npass.\n\n  [1] http://mainisusuallyafunction.blogspot.com/2012/11/attacking-hardened-linux-systems-with.html\n  [2] https://github.com/01org/jit-spray-poc-for-ksp/\n  [3] http://www.openwall.com/lists/kernel-hardening/2016/05/03/5\n\nSigned-off-by: Daniel Borkmann <daniel@iogearbox.net>\nReviewed-by: Elena Reshetova <elena.reshetova@intel.com>\nAcked-by: Alexei Starovoitov <ast@kernel.org>\nSigned-off-by: David S. Miller <davem@davemloft.net>",
  "author_name": "Daniel Borkmann",
  "author_email": "daniel@iogearbox.net",
  "author_date": "Fri May 13 19:08:32 2016 +0200",
  "author_date_iso": "2016-05-13T19:08:32+02:00",
  "committer_name": "David S. Miller",
  "committer_email": "davem@davemloft.net",
  "committer_date": "Mon May 16 13:49:32 2016 -0400",
  "committer_date_iso": "2016-05-16T13:49:32-04:00",
  "files_changed": [
    "Documentation/sysctl/net.txt",
    "include/linux/filter.h",
    "kernel/bpf/core.c",
    "net/Kconfig",
    "net/core/sysctl_net_core.c"
  ],
  "files_changed_count": 5,
  "stats": [
    {
      "file": "Documentation/sysctl/net.txt",
      "insertions": 11,
      "deletions": 0
    },
    {
      "file": "include/linux/filter.h",
      "insertions": 42,
      "deletions": 0
    },
    {
      "file": "kernel/bpf/core.c",
      "insertions": 203,
      "deletions": 0
    },
    {
      "file": "net/Kconfig",
      "insertions": 5,
      "deletions": 2
    },
    {
      "file": "net/core/sysctl_net_core.c",
      "insertions": 9,
      "deletions": 0
    }
  ],
  "total_insertions": 270,
  "total_deletions": 2,
  "total_changes": 272,
  "parents": [
    "d1c55ab5e41fcd72cb0a8bef86d3f652ad9ad9f5"
  ],
  "branches": [
    "* development",
    "master",
    "remotes/origin/HEAD -> origin/master",
    "remotes/origin/master"
  ],
  "tags": [
    "v4.10",
    "v4.10-rc1",
    "v4.10-rc2",
    "v4.10-rc3",
    "v4.10-rc4",
    "v4.10-rc5",
    "v4.10-rc6",
    "v4.10-rc7",
    "v4.10-rc8",
    "v4.11"
  ],
  "is_merge": false,
  "security_info": {
    "cve_ids": [],
    "security_keywords": [
      "hardening",
      "injection"
    ]
  },
  "fix_type": "security",
  "file_results": [
    {
      "file": "Documentation/sysctl/net.txt",
      "pre_version": false,
      "post_version": true,
      "patch": true
    },
    {
      "file": "include/linux/filter.h",
      "pre_version": true,
      "post_version": true,
      "patch": true
    },
    {
      "file": "kernel/bpf/core.c",
      "pre_version": true,
      "post_version": true,
      "patch": true
    },
    {
      "file": "net/Kconfig",
      "pre_version": false,
      "post_version": true,
      "patch": true
    },
    {
      "file": "net/core/sysctl_net_core.c",
      "pre_version": false,
      "post_version": true,
      "patch": true
    }
  ]
}