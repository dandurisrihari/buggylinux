{
  "hash": "abafbc551fddede3e0a08dee1dcde08fc0eb8476",
  "hash_short": "abafbc55",
  "subject": "vfio-pci: Invalidate mmaps and block MMIO access on disabled memory",
  "body": "Accessing the disabled memory space of a PCI device would typically\nresult in a master abort response on conventional PCI, or an\nunsupported request on PCI express.  The user would generally see\nthese as a -1 response for the read return data and the write would be\nsilently discarded, possibly with an uncorrected, non-fatal AER error\ntriggered on the host.  Some systems however take it upon themselves\nto bring down the entire system when they see something that might\nindicate a loss of data, such as this discarded write to a disabled\nmemory space.\n\nTo avoid this, we want to try to block the user from accessing memory\nspaces while they're disabled.  We start with a semaphore around the\nmemory enable bit, where writers modify the memory enable state and\nmust be serialized, while readers make use of the memory region and\ncan access in parallel.  Writers include both direct manipulation via\nthe command register, as well as any reset path where the internal\nmechanics of the reset may both explicitly and implicitly disable\nmemory access, and manipulation of the MSI-X configuration, where the\nMSI-X vector table resides in MMIO space of the device.  Readers\ninclude the read and write file ops to access the vfio device fd\noffsets as well as memory mapped access.  In the latter case, we make\nuse of our new vma list support to zap, or invalidate, those memory\nmappings in order to force them to be faulted back in on access.\n\nOur semaphore usage will stall user access to MMIO spaces across\ninternal operations like reset, but the user might experience new\nbehavior when trying to access the MMIO space while disabled via the\nPCI command register.  Access via read or write while disabled will\nreturn -EIO and access via memory maps will result in a SIGBUS.  This\nis expected to be compatible with known use cases and potentially\nprovides better error handling capabilities than present in the\nhardware, while avoiding the more readily accessible and severe\nplatform error responses that might otherwise occur.\n\nFixes: CVE-2020-12888\nReviewed-by: Peter Xu <peterx@redhat.com>\nSigned-off-by: Alex Williamson <alex.williamson@redhat.com>",
  "full_message": "vfio-pci: Invalidate mmaps and block MMIO access on disabled memory\n\nAccessing the disabled memory space of a PCI device would typically\nresult in a master abort response on conventional PCI, or an\nunsupported request on PCI express.  The user would generally see\nthese as a -1 response for the read return data and the write would be\nsilently discarded, possibly with an uncorrected, non-fatal AER error\ntriggered on the host.  Some systems however take it upon themselves\nto bring down the entire system when they see something that might\nindicate a loss of data, such as this discarded write to a disabled\nmemory space.\n\nTo avoid this, we want to try to block the user from accessing memory\nspaces while they're disabled.  We start with a semaphore around the\nmemory enable bit, where writers modify the memory enable state and\nmust be serialized, while readers make use of the memory region and\ncan access in parallel.  Writers include both direct manipulation via\nthe command register, as well as any reset path where the internal\nmechanics of the reset may both explicitly and implicitly disable\nmemory access, and manipulation of the MSI-X configuration, where the\nMSI-X vector table resides in MMIO space of the device.  Readers\ninclude the read and write file ops to access the vfio device fd\noffsets as well as memory mapped access.  In the latter case, we make\nuse of our new vma list support to zap, or invalidate, those memory\nmappings in order to force them to be faulted back in on access.\n\nOur semaphore usage will stall user access to MMIO spaces across\ninternal operations like reset, but the user might experience new\nbehavior when trying to access the MMIO space while disabled via the\nPCI command register.  Access via read or write while disabled will\nreturn -EIO and access via memory maps will result in a SIGBUS.  This\nis expected to be compatible with known use cases and potentially\nprovides better error handling capabilities than present in the\nhardware, while avoiding the more readily accessible and severe\nplatform error responses that might otherwise occur.\n\nFixes: CVE-2020-12888\nReviewed-by: Peter Xu <peterx@redhat.com>\nSigned-off-by: Alex Williamson <alex.williamson@redhat.com>",
  "author_name": "Alex Williamson",
  "author_email": "alex.williamson@redhat.com",
  "author_date": "Wed Apr 22 13:48:11 2020 -0600",
  "author_date_iso": "2020-04-22T13:48:11-06:00",
  "committer_name": "Alex Williamson",
  "committer_email": "alex.williamson@redhat.com",
  "committer_date": "Mon May 18 09:53:38 2020 -0600",
  "committer_date_iso": "2020-05-18T09:53:38-06:00",
  "files_changed": [
    "drivers/vfio/pci/vfio_pci.c",
    "drivers/vfio/pci/vfio_pci_config.c",
    "drivers/vfio/pci/vfio_pci_intrs.c",
    "drivers/vfio/pci/vfio_pci_private.h",
    "drivers/vfio/pci/vfio_pci_rdwr.c"
  ],
  "files_changed_count": 5,
  "stats": [
    {
      "file": "drivers/vfio/pci/vfio_pci.c",
      "insertions": 258,
      "deletions": 33
    },
    {
      "file": "drivers/vfio/pci/vfio_pci_config.c",
      "insertions": 30,
      "deletions": 6
    },
    {
      "file": "drivers/vfio/pci/vfio_pci_intrs.c",
      "insertions": 14,
      "deletions": 0
    },
    {
      "file": "drivers/vfio/pci/vfio_pci_private.h",
      "insertions": 8,
      "deletions": 0
    },
    {
      "file": "drivers/vfio/pci/vfio_pci_rdwr.c",
      "insertions": 20,
      "deletions": 4
    }
  ],
  "total_insertions": 330,
  "total_deletions": 43,
  "total_changes": 373,
  "parents": [
    "11c4cd07ba111a09f49625f9e4c851d83daf0a22"
  ],
  "branches": [
    "* development",
    "remotes/origin/HEAD -> origin/master",
    "remotes/origin/master"
  ],
  "tags": [],
  "is_merge": false,
  "security_info": {
    "cve_ids": [
      "CVE-2020-12888"
    ],
    "security_keywords": []
  },
  "fix_type": "cve",
  "file_results": [
    {
      "file": "drivers/vfio/pci/vfio_pci.c",
      "pre_version": true,
      "post_version": true,
      "patch": true
    },
    {
      "file": "drivers/vfio/pci/vfio_pci_config.c",
      "pre_version": false,
      "post_version": true,
      "patch": true
    },
    {
      "file": "drivers/vfio/pci/vfio_pci_intrs.c",
      "pre_version": false,
      "post_version": true,
      "patch": true
    },
    {
      "file": "drivers/vfio/pci/vfio_pci_private.h",
      "pre_version": true,
      "post_version": true,
      "patch": true
    },
    {
      "file": "drivers/vfio/pci/vfio_pci_rdwr.c",
      "pre_version": false,
      "post_version": true,
      "patch": true
    }
  ]
}