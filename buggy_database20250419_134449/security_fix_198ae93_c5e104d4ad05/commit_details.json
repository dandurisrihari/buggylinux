{
  "hash": "198ae936efdba33cf5e5cfb28986c9376179fd23",
  "hash_short": "198ae936",
  "subject": "Merge branch 'optimize-zext'",
  "body": "Jiong Wang says:\n\n====================\nv9:\n  - Split patch 5 in v8.\n    make bpf uapi header file sync a separate patch. (Alexei)\n\nv8:\n  - For stack slot read, mark them as REG_LIVE_READ64. (Alexei)\n  - Change DEF_NOT_SUBREG from -1 to 0. (Alexei)\n  - Rebased on top of latest bpf-next.\n\nv7:\n  - Drop the first patch in v6, the one adding 32-bit return value and\n    argument type. (Alexei)\n  - Rename bpf_jit_hardware_zext to bpf_jit_needs_zext. (Alexei)\n  - Use mov32 with imm == 1 to indicate it is zext. (Alexei)\n  - JIT back-ends peephole next insn to optimize out unnecessary zext\n    inserted by verifier. (Alexei)\n  - Testing:\n    + patch set tested (bpf selftest) on x64 host with llvm 9.0\n      no regression observed no both JIT and interpreter modes.\n    + patch set tested (bpf selftest) on x32 host.\n      By Yanqing Wang, thanks!\n      no regression observed on both JIT and interpreter modes.\n    + patch set tested (bpf selftest) on RV64 host with llvm 9.0,\n      By Bj\u00f6rn T\u00f6pel, thanks!\n      no regression observed before and after this set with JIT_ALWAYS_ON.\n      test_progs_32 also enabled as LLVM 9.0 is used by Bj\u00f6rn.\n    + cross compiled the other affected targets, arm, PowerPC, SPARC, S390.\n\nv6:\n  - Fixed s390 kbuild test robot error. (kbuild)\n  - Make comment style in backends patches more consistent.\n\nv5:\n  - Adjusted several test_verifier helpers to make them works on hosts\n    w and w/o hardware zext. (Naveen)\n  - Make sure zext flag not set when verifier by-passed, for example,\n    libtest_bpf.ko. (Naveen)\n  - Conservatively mark bpf main return value as 64-bit. (Alexei)\n  - Make sure read flag is either READ64 or READ32, not the mix of both.\n    (Alexei)\n  - Merged patch 1 and 2 in v4. (Alexei)\n  - Fixed kbuild test robot warning on NFP. (kbuild)\n  - Proposed new BPF_ZEXT insn to have optimal code-gen for various JIT\n    back-ends.\n  - Conservately set zext flags for patched-insn.\n  - Fixed return value zext for helper function calls.\n  - Also adjusted test_verifier scalability unit test to avoid triggerring\n    too many insn patch which will hang computer.\n  - re-tested on x86 host with llvm 9.0, no regression on test_verifier,\n    test_progs, test_progs_32.\n  - re-tested offload target (nfp), no regression on local testsuite.\n\nv4:\n  - added the two missing fixes which addresses two Jakub's reviewes in v3.\n  - rebase on top of bpf-next.\n\nv3:\n  - remove redundant check in \"propagate_liveness_reg\". (Jakub)\n  - add extra check in \"mark_reg_read\" to prune more search. (Jakub)\n  - re-implemented \"prog_flags\" passing mechanism, removed use of\n    global switch inside libbpf.\n  - enabled high 32-bit randomization beyond \"test_verifier\" and\n    \"test_progs\". Now it should have been enabled for all possible\n    tests. Re-run all tests, haven't noticed regression.\n  - remove RFC tag.\n\nv2:\n  - rebased on top of bpf-next master.\n  - added comments for what is sub-register def index. (Edward, Alexei)\n  - removed patch 1 which turns bit mask from enum to macro. (Alexei)\n  - removed sysctl/bpf_jit_32bit_opt. (Alexei)\n  - merged sub-register def insn index into reg state. (Alexei)\n  - change test methodology (Alexei):\n      + instead of simple unit tests on x86_64 for which this optimization\n        doesn't enabled due to there is hardware support, poison high\n        32-bit for whose def identified as safe to do so. this could let\n        the correctness of this patch set checked when daily bpf selftest\n        ran which delivers very stressful test on host machine like x86_64.\n      + hi32 poisoning is gated by a new BPF_F_TEST_RND_HI32 prog flags.\n      + BPF_F_TEST_RND_HI32 is enabled for all tests of \"test_progs\" and\n        \"test_verifier\", the latter needs minor tweak on two unit tests,\n        please see the patch for the change.\n      + introduced a new global variable \"libbpf_test_mode\" into libbpf.\n        once it is set to true, it will set BPF_F_TEST_RND_HI32 for all the\n        later PROG_LOAD syscall, the goal is to easy the enable of hi32\n        poison on exsiting testsuite.\n        we could also introduce new APIs, for example \"bpf_prog_test_load\",\n        then use -Dbpf_prog_load=bpf_prog_test_load to migrate tests under\n        test_progs, but there are several load APIs, and such new API need\n        some change on struture like \"struct bpf_prog_load_attr\".\n      + removed old unit tests. it is based on insn scan and requires quite\n        a few test_verifier generic code change. given hi32 randomization\n        could offer good test coverage, the unit tests doesn't add much\n        extra test value.\n  - enhanced register width check (\"is_reg64\") when record sub-register\n    write, now, it returns more accurate width.\n  - Re-run all tests under \"test_progs\" and \"test_verifier\" on x86_64, no\n    regression. Fixed a couple of bugs exposed:\n      1. ctx field size transformation was not taken into account.\n      2. insn patch could cause lost of original aux data which is\n         important for ctx field conversion.\n      3. return value for propagate_liveness was wrong and caused\n         regression on processed insn number.\n      4. helper call arg wasn't handled properly that path prune may cause\n         64-bit read info in pruned path lost.\n  - Re-run Cilium bpf prog for processed-insn-number benchmarking, no\n    regression.\n\nv1:\n  - Fixed the missing handling on callee-saved for bpf-to-bpf call,\n    sub-register defs therefore moved to frame state. (Jakub Kicinski)\n  - Removed redundant \"cross_reg\". (Jakub Kicinski)\n  - Various coding styles & grammar fixes. (Jakub Kicinski, Quentin Monnet)\n\neBPF ISA specification requires high 32-bit cleared when low 32-bit\nsub-register is written. This applies to destination register of ALU32 etc.\nJIT back-ends must guarantee this semantic when doing code-gen. x86_64 and\nAArch64 ISA has the same semantics, so the corresponding JIT back-end\ndoesn't need to do extra work.\n\nHowever, 32-bit arches (arm, x86, nfp etc.) and some other 64-bit arches\n(PowerPC, SPARC etc) need to do explicit zero extension to meet this\nrequirement, otherwise code like the following will fail.\n\n  u64_value = (u64) u32_value\n  ... other uses of u64_value\n\nThis is because compiler could exploit the semantic described above and\nsave those zero extensions for extending u32_value to u64_value, these JIT\nback-ends are expected to guarantee this through inserting extra zero\nextensions which however could be a significant increase on the code size.\nSome benchmarks show there could be ~40% sub-register writes out of total\ninsns, meaning at least ~40% extra code-gen.\n\nOne observation is these extra zero extensions are not always necessary.\nTake above code snippet for example, it is possible u32_value will never be\ncasted into a u64, the value of high 32-bit of u32_value then could be\nignored and extra zero extension could be eliminated.\n\nThis patch implements this idea, insns defining sub-registers will be\nmarked when the high 32-bit of the defined sub-register matters. For\nthose unmarked insns, it is safe to eliminate high 32-bit clearnace for\nthem.\n\nAlgo\n====\nWe could use insn scan based static analysis to tell whether one\nsub-register def doesn't need zero extension. However, using such static\nanalysis, we must do conservative assumption at branching point where\nmultiple uses could be introduced. So, for any sub-register def that is\nactive at branching point, we need to mark it as needing zero extension.\nThis could introducing quite a few false alarms, for example ~25% on\nCilium bpf_lxc.\n\nIt will be far better to use dynamic data-flow tracing which verifier\nfortunately already has and could be easily extend to serve the purpose of\nthis patch set.\n\n - Split read flags into READ32 and READ64.\n\n - Record index of insn that does sub-register write. Keep the index inside\n   reg state and update it during verifier insn walking.\n\n - A full register read on a sub-register marks its definition insn as\n   needing zero extension on dst register.\n\n   A new sub-register write overrides the old one.\n\n - When propagating read64 during path pruning, also mark any insn defining\n   a sub-register that is read in the pruned path as full-register.\n\nBenchmark\n=========\n - I estimate the JITed image could be 10% ~ 30% smaller on these affected\n   arches (nfp, arm, x32, risv, ppc, sparc, s390), depending on the prog.\n\n - For Cilium bpf_lxc, there is ~11500 insns in the compiled binary (use\n   latest LLVM snapshot, and with -mcpu=v3 -mattr=+alu32 enabled), 4460 of\n   them has sub-register writes (~40%). Calculated by:\n\n    cat dump | grep -P \"\\tw\" | wc -l       (ALU32)\n    cat dump | grep -P \"r.*=.*u32\" | wc -l (READ_W)\n    cat dump | grep -P \"r.*=.*u16\" | wc -l (READ_H)\n    cat dump | grep -P \"r.*=.*u8\" | wc -l  (READ_B)\n\n   After this patch set enabled, > 25% of those 4460 could be identified as\n   doesn't needing zero extension on the destination, and the percentage\n   could go further up to more than 50% with some follow up optimizations\n   based on the infrastructure offered by this set. This leads to\n   significant save on JITed image.\n====================\n\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>",
  "full_message": "Merge branch 'optimize-zext'\n\nJiong Wang says:\n\n====================\nv9:\n  - Split patch 5 in v8.\n    make bpf uapi header file sync a separate patch. (Alexei)\n\nv8:\n  - For stack slot read, mark them as REG_LIVE_READ64. (Alexei)\n  - Change DEF_NOT_SUBREG from -1 to 0. (Alexei)\n  - Rebased on top of latest bpf-next.\n\nv7:\n  - Drop the first patch in v6, the one adding 32-bit return value and\n    argument type. (Alexei)\n  - Rename bpf_jit_hardware_zext to bpf_jit_needs_zext. (Alexei)\n  - Use mov32 with imm == 1 to indicate it is zext. (Alexei)\n  - JIT back-ends peephole next insn to optimize out unnecessary zext\n    inserted by verifier. (Alexei)\n  - Testing:\n    + patch set tested (bpf selftest) on x64 host with llvm 9.0\n      no regression observed no both JIT and interpreter modes.\n    + patch set tested (bpf selftest) on x32 host.\n      By Yanqing Wang, thanks!\n      no regression observed on both JIT and interpreter modes.\n    + patch set tested (bpf selftest) on RV64 host with llvm 9.0,\n      By Bj\u00f6rn T\u00f6pel, thanks!\n      no regression observed before and after this set with JIT_ALWAYS_ON.\n      test_progs_32 also enabled as LLVM 9.0 is used by Bj\u00f6rn.\n    + cross compiled the other affected targets, arm, PowerPC, SPARC, S390.\n\nv6:\n  - Fixed s390 kbuild test robot error. (kbuild)\n  - Make comment style in backends patches more consistent.\n\nv5:\n  - Adjusted several test_verifier helpers to make them works on hosts\n    w and w/o hardware zext. (Naveen)\n  - Make sure zext flag not set when verifier by-passed, for example,\n    libtest_bpf.ko. (Naveen)\n  - Conservatively mark bpf main return value as 64-bit. (Alexei)\n  - Make sure read flag is either READ64 or READ32, not the mix of both.\n    (Alexei)\n  - Merged patch 1 and 2 in v4. (Alexei)\n  - Fixed kbuild test robot warning on NFP. (kbuild)\n  - Proposed new BPF_ZEXT insn to have optimal code-gen for various JIT\n    back-ends.\n  - Conservately set zext flags for patched-insn.\n  - Fixed return value zext for helper function calls.\n  - Also adjusted test_verifier scalability unit test to avoid triggerring\n    too many insn patch which will hang computer.\n  - re-tested on x86 host with llvm 9.0, no regression on test_verifier,\n    test_progs, test_progs_32.\n  - re-tested offload target (nfp), no regression on local testsuite.\n\nv4:\n  - added the two missing fixes which addresses two Jakub's reviewes in v3.\n  - rebase on top of bpf-next.\n\nv3:\n  - remove redundant check in \"propagate_liveness_reg\". (Jakub)\n  - add extra check in \"mark_reg_read\" to prune more search. (Jakub)\n  - re-implemented \"prog_flags\" passing mechanism, removed use of\n    global switch inside libbpf.\n  - enabled high 32-bit randomization beyond \"test_verifier\" and\n    \"test_progs\". Now it should have been enabled for all possible\n    tests. Re-run all tests, haven't noticed regression.\n  - remove RFC tag.\n\nv2:\n  - rebased on top of bpf-next master.\n  - added comments for what is sub-register def index. (Edward, Alexei)\n  - removed patch 1 which turns bit mask from enum to macro. (Alexei)\n  - removed sysctl/bpf_jit_32bit_opt. (Alexei)\n  - merged sub-register def insn index into reg state. (Alexei)\n  - change test methodology (Alexei):\n      + instead of simple unit tests on x86_64 for which this optimization\n        doesn't enabled due to there is hardware support, poison high\n        32-bit for whose def identified as safe to do so. this could let\n        the correctness of this patch set checked when daily bpf selftest\n        ran which delivers very stressful test on host machine like x86_64.\n      + hi32 poisoning is gated by a new BPF_F_TEST_RND_HI32 prog flags.\n      + BPF_F_TEST_RND_HI32 is enabled for all tests of \"test_progs\" and\n        \"test_verifier\", the latter needs minor tweak on two unit tests,\n        please see the patch for the change.\n      + introduced a new global variable \"libbpf_test_mode\" into libbpf.\n        once it is set to true, it will set BPF_F_TEST_RND_HI32 for all the\n        later PROG_LOAD syscall, the goal is to easy the enable of hi32\n        poison on exsiting testsuite.\n        we could also introduce new APIs, for example \"bpf_prog_test_load\",\n        then use -Dbpf_prog_load=bpf_prog_test_load to migrate tests under\n        test_progs, but there are several load APIs, and such new API need\n        some change on struture like \"struct bpf_prog_load_attr\".\n      + removed old unit tests. it is based on insn scan and requires quite\n        a few test_verifier generic code change. given hi32 randomization\n        could offer good test coverage, the unit tests doesn't add much\n        extra test value.\n  - enhanced register width check (\"is_reg64\") when record sub-register\n    write, now, it returns more accurate width.\n  - Re-run all tests under \"test_progs\" and \"test_verifier\" on x86_64, no\n    regression. Fixed a couple of bugs exposed:\n      1. ctx field size transformation was not taken into account.\n      2. insn patch could cause lost of original aux data which is\n         important for ctx field conversion.\n      3. return value for propagate_liveness was wrong and caused\n         regression on processed insn number.\n      4. helper call arg wasn't handled properly that path prune may cause\n         64-bit read info in pruned path lost.\n  - Re-run Cilium bpf prog for processed-insn-number benchmarking, no\n    regression.\n\nv1:\n  - Fixed the missing handling on callee-saved for bpf-to-bpf call,\n    sub-register defs therefore moved to frame state. (Jakub Kicinski)\n  - Removed redundant \"cross_reg\". (Jakub Kicinski)\n  - Various coding styles & grammar fixes. (Jakub Kicinski, Quentin Monnet)\n\neBPF ISA specification requires high 32-bit cleared when low 32-bit\nsub-register is written. This applies to destination register of ALU32 etc.\nJIT back-ends must guarantee this semantic when doing code-gen. x86_64 and\nAArch64 ISA has the same semantics, so the corresponding JIT back-end\ndoesn't need to do extra work.\n\nHowever, 32-bit arches (arm, x86, nfp etc.) and some other 64-bit arches\n(PowerPC, SPARC etc) need to do explicit zero extension to meet this\nrequirement, otherwise code like the following will fail.\n\n  u64_value = (u64) u32_value\n  ... other uses of u64_value\n\nThis is because compiler could exploit the semantic described above and\nsave those zero extensions for extending u32_value to u64_value, these JIT\nback-ends are expected to guarantee this through inserting extra zero\nextensions which however could be a significant increase on the code size.\nSome benchmarks show there could be ~40% sub-register writes out of total\ninsns, meaning at least ~40% extra code-gen.\n\nOne observation is these extra zero extensions are not always necessary.\nTake above code snippet for example, it is possible u32_value will never be\ncasted into a u64, the value of high 32-bit of u32_value then could be\nignored and extra zero extension could be eliminated.\n\nThis patch implements this idea, insns defining sub-registers will be\nmarked when the high 32-bit of the defined sub-register matters. For\nthose unmarked insns, it is safe to eliminate high 32-bit clearnace for\nthem.\n\nAlgo\n====\nWe could use insn scan based static analysis to tell whether one\nsub-register def doesn't need zero extension. However, using such static\nanalysis, we must do conservative assumption at branching point where\nmultiple uses could be introduced. So, for any sub-register def that is\nactive at branching point, we need to mark it as needing zero extension.\nThis could introducing quite a few false alarms, for example ~25% on\nCilium bpf_lxc.\n\nIt will be far better to use dynamic data-flow tracing which verifier\nfortunately already has and could be easily extend to serve the purpose of\nthis patch set.\n\n - Split read flags into READ32 and READ64.\n\n - Record index of insn that does sub-register write. Keep the index inside\n   reg state and update it during verifier insn walking.\n\n - A full register read on a sub-register marks its definition insn as\n   needing zero extension on dst register.\n\n   A new sub-register write overrides the old one.\n\n - When propagating read64 during path pruning, also mark any insn defining\n   a sub-register that is read in the pruned path as full-register.\n\nBenchmark\n=========\n - I estimate the JITed image could be 10% ~ 30% smaller on these affected\n   arches (nfp, arm, x32, risv, ppc, sparc, s390), depending on the prog.\n\n - For Cilium bpf_lxc, there is ~11500 insns in the compiled binary (use\n   latest LLVM snapshot, and with -mcpu=v3 -mattr=+alu32 enabled), 4460 of\n   them has sub-register writes (~40%). Calculated by:\n\n    cat dump | grep -P \"\\tw\" | wc -l       (ALU32)\n    cat dump | grep -P \"r.*=.*u32\" | wc -l (READ_W)\n    cat dump | grep -P \"r.*=.*u16\" | wc -l (READ_H)\n    cat dump | grep -P \"r.*=.*u8\" | wc -l  (READ_B)\n\n   After this patch set enabled, > 25% of those 4460 could be identified as\n   doesn't needing zero extension on the destination, and the percentage\n   could go further up to more than 50% with some follow up optimizations\n   based on the infrastructure offered by this set. This leads to\n   significant save on JITed image.\n====================\n\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>",
  "author_name": "Alexei Starovoitov",
  "author_email": "ast@kernel.org",
  "author_date": "Fri May 24 18:58:59 2019 -0700",
  "author_date_iso": "2019-05-24T18:58:59-07:00",
  "committer_name": "Alexei Starovoitov",
  "committer_email": "ast@kernel.org",
  "committer_date": "Fri May 24 18:59:00 2019 -0700",
  "committer_date_iso": "2019-05-24T18:59:00-07:00",
  "files_changed": [],
  "files_changed_count": 0,
  "stats": [
    {
      "file": "arch/arm/net/bpf_jit_32.c",
      "insertions": 31,
      "deletions": 11
    },
    {
      "file": "arch/powerpc/net/bpf_jit_comp64.c",
      "insertions": 33,
      "deletions": 3
    },
    {
      "file": "arch/riscv/net/bpf_jit_comp.c",
      "insertions": 30,
      "deletions": 13
    },
    {
      "file": "arch/s390/net/bpf_jit_comp.c",
      "insertions": 34,
      "deletions": 7
    },
    {
      "file": "arch/sparc/net/bpf_jit_comp_64.c",
      "insertions": 27,
      "deletions": 2
    },
    {
      "file": "arch/x86/net/bpf_jit_comp32.c",
      "insertions": 56,
      "deletions": 27
    },
    {
      "file": "drivers/net/ethernet/netronome/nfp/bpf/jit.c",
      "insertions": 67,
      "deletions": 48
    },
    {
      "file": "drivers/net/ethernet/netronome/nfp/bpf/main.h",
      "insertions": 2,
      "deletions": 0
    },
    {
      "file": "drivers/net/ethernet/netronome/nfp/bpf/verifier.c",
      "insertions": 12,
      "deletions": 0
    },
    {
      "file": "include/linux/bpf.h",
      "insertions": 1,
      "deletions": 0
    },
    {
      "file": "include/linux/bpf_verifier.h",
      "insertions": 11,
      "deletions": 3
    },
    {
      "file": "include/linux/filter.h",
      "insertions": 15,
      "deletions": 0
    },
    {
      "file": "include/uapi/linux/bpf.h",
      "insertions": 18,
      "deletions": 0
    },
    {
      "file": "kernel/bpf/core.c",
      "insertions": 9,
      "deletions": 0
    },
    {
      "file": "kernel/bpf/syscall.c",
      "insertions": 3,
      "deletions": 1
    },
    {
      "file": "kernel/bpf/verifier.c",
      "insertions": 280,
      "deletions": 17
    },
    {
      "file": "tools/include/uapi/linux/bpf.h",
      "insertions": 18,
      "deletions": 0
    },
    {
      "file": "tools/lib/bpf/bpf.c",
      "insertions": 1,
      "deletions": 0
    },
    {
      "file": "tools/lib/bpf/bpf.h",
      "insertions": 1,
      "deletions": 0
    },
    {
      "file": "tools/lib/bpf/libbpf.c",
      "insertions": 3,
      "deletions": 0
    },
    {
      "file": "tools/lib/bpf/libbpf.h",
      "insertions": 1,
      "deletions": 0
    },
    {
      "file": "tools/testing/selftests/bpf/Makefile",
      "insertions": 6,
      "deletions": 4
    },
    {
      "file": "tools/testing/selftests/bpf/prog_tests/bpf_verif_scale.c",
      "insertions": 1,
      "deletions": 0
    },
    {
      "file": "tools/testing/selftests/bpf/test_sock_addr.c",
      "insertions": 1,
      "deletions": 0
    },
    {
      "file": "tools/testing/selftests/bpf/test_sock_fields.c",
      "insertions": 1,
      "deletions": 0
    },
    {
      "file": "tools/testing/selftests/bpf/test_socket_cookie.c",
      "insertions": 1,
      "deletions": 0
    },
    {
      "file": "tools/testing/selftests/bpf/test_stub.c",
      "insertions": 40,
      "deletions": 0
    },
    {
      "file": "tools/testing/selftests/bpf/test_verifier.c",
      "insertions": 20,
      "deletions": 11
    }
  ],
  "total_insertions": 723,
  "total_deletions": 147,
  "total_changes": 870,
  "parents": [
    "a08acd118d5ca7f6e745ef81cfc6cbadacb56462",
    "0b4de1ff19bf878eb38f4f668ee15c9b9eed4240"
  ],
  "branches": [
    "* development",
    "master",
    "remotes/origin/HEAD -> origin/master",
    "remotes/origin/master"
  ],
  "tags": [
    "v5.3",
    "v5.3-rc1",
    "v5.3-rc2",
    "v5.3-rc3",
    "v5.3-rc4",
    "v5.3-rc5",
    "v5.3-rc6",
    "v5.3-rc7",
    "v5.3-rc8",
    "v5.4"
  ],
  "is_merge": true,
  "security_info": {
    "cve_ids": [],
    "security_keywords": [
      "exploit"
    ]
  },
  "fix_type": "security",
  "file_results": []
}