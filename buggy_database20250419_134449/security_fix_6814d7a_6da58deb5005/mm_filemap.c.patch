commit 6814d7a91289ceb143285975e244a8f00fd3a830
Author: Andrew Morton <akpm@osdl.org>
Date:   Tue Oct 16 01:24:54 2007 -0700

    Revert "[PATCH] generic_file_buffered_write(): deadlock on vectored write"
    
    This reverts commit 6527c2bdf1f833cc18e8f42bd97973d583e4aa83, which
    fixed the following bug:
    
      When prefaulting in the pages in generic_file_buffered_write(), we only
      faulted in the pages for the firts segment of the iovec.  If the second of
      successive segment described a mmapping of the page into which we're
      write()ing, and that page is not up-to-date, the fault handler tries to lock
      the already-locked page (to bring it up to date) and deadlocks.
    
      An exploit for this bug is in writev-deadlock-demo.c, in
      http://www.zip.com.au/~akpm/linux/patches/stuff/ext3-tools.tar.gz.
    
      (These demos assume blocksize < PAGE_CACHE_SIZE).
    
    The problem with this fix is that it takes the kernel back to doing a single
    prepare_write()/commit_write() per iovec segment.  So in the worst case we'll
    run prepare_write+commit_write 1024 times where we previously would have run
    it once. The other problem with the fix is that it fix all the locking problems.
    
    <insert numbers obtained via ext3-tools's writev-speed.c here>
    
    And apparently this change killed NFS overwrite performance, because, I
    suppose, it talks to the server for each prepare_write+commit_write.
    
    So just back that patch out - we'll be fixing the deadlock by other means.
    
    Nick says: also it only ever actually papered over the bug, because after
    faulting in the pages, they might be unmapped or reclaimed.
    
    Signed-off-by: Nick Piggin <npiggin@suse.de>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/mm/filemap.c b/mm/filemap.c
index caaaa7adfdf9..4bf7d1ab6c2a 100644
--- a/mm/filemap.c
+++ b/mm/filemap.c
@@ -1865,21 +1865,14 @@ generic_file_buffered_write(struct kiocb *iocb, const struct iovec *iov,
 	do {
 		unsigned long index;
 		unsigned long offset;
+		unsigned long maxlen;
 		size_t copied;
 
 		offset = (pos & (PAGE_CACHE_SIZE -1)); /* Within page */
 		index = pos >> PAGE_CACHE_SHIFT;
 		bytes = PAGE_CACHE_SIZE - offset;
-
-		/* Limit the size of the copy to the caller's write size */
-		bytes = min(bytes, count);
-
-		/*
-		 * Limit the size of the copy to that of the current segment,
-		 * because fault_in_pages_readable() doesn't know how to walk
-		 * segments.
-		 */
-		bytes = min(bytes, cur_iov->iov_len - iov_base);
+		if (bytes > count)
+			bytes = count;
 
 		/*
 		 * Bring in the user page that we will copy from _first_.
@@ -1887,7 +1880,10 @@ generic_file_buffered_write(struct kiocb *iocb, const struct iovec *iov,
 		 * same page as we're writing to, without it being marked
 		 * up-to-date.
 		 */
-		fault_in_pages_readable(buf, bytes);
+		maxlen = cur_iov->iov_len - iov_base;
+		if (maxlen > bytes)
+			maxlen = bytes;
+		fault_in_pages_readable(buf, maxlen);
 
 		page = __grab_cache_page(mapping,index,&cached_page,&lru_pvec);
 		if (!page) {