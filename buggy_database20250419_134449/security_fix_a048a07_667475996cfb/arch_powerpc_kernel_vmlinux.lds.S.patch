commit a048a07d7f4535baa4cbad6bc024f175317ab938
Author: Nicholas Piggin <npiggin@gmail.com>
Date:   Tue May 22 09:00:00 2018 +1000

    powerpc/64s: Add support for a store forwarding barrier at kernel entry/exit
    
    On some CPUs we can prevent a vulnerability related to store-to-load
    forwarding by preventing store forwarding between privilege domains,
    by inserting a barrier in kernel entry and exit paths.
    
    This is known to be the case on at least Power7, Power8 and Power9
    powerpc CPUs.
    
    Barriers must be inserted generally before the first load after moving
    to a higher privilege, and after the last store before moving to a
    lower privilege, HV and PR privilege transitions must be protected.
    
    Barriers are added as patch sections, with all kernel/hypervisor entry
    points patched, and the exit points to lower privilge levels patched
    similarly to the RFI flush patching.
    
    Firmware advertisement is not implemented yet, so CPU flush types
    are hard coded.
    
    Thanks to Michal Suchánek for bug fixes and review.
    
    Signed-off-by: Nicholas Piggin <npiggin@gmail.com>
    Signed-off-by: Mauricio Faria de Oliveira <mauricfo@linux.vnet.ibm.com>
    Signed-off-by: Michael Neuling <mikey@neuling.org>
    Signed-off-by: Michal Suchánek <msuchanek@suse.de>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/powerpc/kernel/vmlinux.lds.S b/arch/powerpc/kernel/vmlinux.lds.S
index c8af90ff49f0..b8d82678f8b4 100644
--- a/arch/powerpc/kernel/vmlinux.lds.S
+++ b/arch/powerpc/kernel/vmlinux.lds.S
@@ -133,6 +133,20 @@ SECTIONS
 	RO_DATA(PAGE_SIZE)
 
 #ifdef CONFIG_PPC64
+	. = ALIGN(8);
+	__stf_entry_barrier_fixup : AT(ADDR(__stf_entry_barrier_fixup) - LOAD_OFFSET) {
+		__start___stf_entry_barrier_fixup = .;
+		*(__stf_entry_barrier_fixup)
+		__stop___stf_entry_barrier_fixup = .;
+	}
+
+	. = ALIGN(8);
+	__stf_exit_barrier_fixup : AT(ADDR(__stf_exit_barrier_fixup) - LOAD_OFFSET) {
+		__start___stf_exit_barrier_fixup = .;
+		*(__stf_exit_barrier_fixup)
+		__stop___stf_exit_barrier_fixup = .;
+	}
+
 	. = ALIGN(8);
 	__rfi_flush_fixup : AT(ADDR(__rfi_flush_fixup) - LOAD_OFFSET) {
 		__start___rfi_flush_fixup = .;