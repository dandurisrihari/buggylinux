commit f79643787e0a0762d2409b7b8334e83f22d85695
Author: Nicholas Piggin <npiggin@gmail.com>
Date:   Tue Nov 17 16:59:12 2020 +1100

    powerpc/64s: flush L1D on kernel entry
    
    IBM Power9 processors can speculatively operate on data in the L1 cache
    before it has been completely validated, via a way-prediction mechanism. It
    is not possible for an attacker to determine the contents of impermissible
    memory using this method, since these systems implement a combination of
    hardware and software security measures to prevent scenarios where
    protected data could be leaked.
    
    However these measures don't address the scenario where an attacker induces
    the operating system to speculatively execute instructions using data that
    the attacker controls. This can be used for example to speculatively bypass
    "kernel user access prevention" techniques, as discovered by Anthony
    Steinhauser of Google's Safeside Project. This is not an attack by itself,
    but there is a possibility it could be used in conjunction with
    side-channels or other weaknesses in the privileged code to construct an
    attack.
    
    This issue can be mitigated by flushing the L1 cache between privilege
    boundaries of concern. This patch flushes the L1 cache on kernel entry.
    
    This is part of the fix for CVE-2020-4788.
    
    Signed-off-by: Nicholas Piggin <npiggin@gmail.com>
    Signed-off-by: Daniel Axtens <dja@axtens.net>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/kernel/exceptions-64s.S b/arch/powerpc/kernel/exceptions-64s.S
index f7d748b88705..5577dd887d37 100644
--- a/arch/powerpc/kernel/exceptions-64s.S
+++ b/arch/powerpc/kernel/exceptions-64s.S
@@ -2951,6 +2951,43 @@ TRAMP_REAL_BEGIN(stf_barrier_fallback)
 	.endr
 	blr
 
+TRAMP_REAL_BEGIN(entry_flush_fallback)
+	std	r9,PACA_EXRFI+EX_R9(r13)
+	std	r10,PACA_EXRFI+EX_R10(r13)
+	std	r11,PACA_EXRFI+EX_R11(r13)
+	mfctr	r9
+	ld	r10,PACA_RFI_FLUSH_FALLBACK_AREA(r13)
+	ld	r11,PACA_L1D_FLUSH_SIZE(r13)
+	srdi	r11,r11,(7 + 3) /* 128 byte lines, unrolled 8x */
+	mtctr	r11
+	DCBT_BOOK3S_STOP_ALL_STREAM_IDS(r11) /* Stop prefetch streams */
+
+	/* order ld/st prior to dcbt stop all streams with flushing */
+	sync
+
+	/*
+	 * The load addresses are at staggered offsets within cachelines,
+	 * which suits some pipelines better (on others it should not
+	 * hurt).
+	 */
+1:
+	ld	r11,(0x80 + 8)*0(r10)
+	ld	r11,(0x80 + 8)*1(r10)
+	ld	r11,(0x80 + 8)*2(r10)
+	ld	r11,(0x80 + 8)*3(r10)
+	ld	r11,(0x80 + 8)*4(r10)
+	ld	r11,(0x80 + 8)*5(r10)
+	ld	r11,(0x80 + 8)*6(r10)
+	ld	r11,(0x80 + 8)*7(r10)
+	addi	r10,r10,0x80*8
+	bdnz	1b
+
+	mtctr	r9
+	ld	r9,PACA_EXRFI+EX_R9(r13)
+	ld	r10,PACA_EXRFI+EX_R10(r13)
+	ld	r11,PACA_EXRFI+EX_R11(r13)
+	blr
+
 TRAMP_REAL_BEGIN(rfi_flush_fallback)
 	SET_SCRATCH0(r13);
 	GET_PACA(r13);