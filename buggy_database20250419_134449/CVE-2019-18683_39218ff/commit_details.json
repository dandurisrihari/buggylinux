{
  "hash": "39218ff4c625dbf2e68224024fe0acaa60bcd51a",
  "hash_short": "39218ff4",
  "subject": "stack: Optionally randomize kernel stack offset each syscall",
  "body": "This provides the ability for architectures to enable kernel stack base\naddress offset randomization. This feature is controlled by the boot\nparam \"randomize_kstack_offset=on/off\", with its default value set by\nCONFIG_RANDOMIZE_KSTACK_OFFSET_DEFAULT.\n\nThis feature is based on the original idea from the last public release\nof PaX's RANDKSTACK feature: https://pax.grsecurity.net/docs/randkstack.txt\nAll the credit for the original idea goes to the PaX team. Note that\nthe design and implementation of this upstream randomize_kstack_offset\nfeature differs greatly from the RANDKSTACK feature (see below).\n\nReasoning for the feature:\n\nThis feature aims to make harder the various stack-based attacks that\nrely on deterministic stack structure. We have had many such attacks in\npast (just to name few):\n\nhttps://jon.oberheide.org/files/infiltrate12-thestackisback.pdf\nhttps://jon.oberheide.org/files/stackjacking-infiltrate11.pdf\nhttps://googleprojectzero.blogspot.com/2016/06/exploiting-recursion-in-linux-kernel_20.html\n\nAs Linux kernel stack protections have been constantly improving\n(vmap-based stack allocation with guard pages, removal of thread_info,\nSTACKLEAK), attackers have had to find new ways for their exploits\nto work. They have done so, continuing to rely on the kernel's stack\ndeterminism, in situations where VMAP_STACK and THREAD_INFO_IN_TASK_STRUCT\nwere not relevant. For example, the following recent attacks would have\nbeen hampered if the stack offset was non-deterministic between syscalls:\n\nhttps://repositorio-aberto.up.pt/bitstream/10216/125357/2/374717.pdf\n(page 70: targeting the pt_regs copy with linear stack overflow)\n\nhttps://a13xp0p0v.github.io/2020/02/15/CVE-2019-18683.html\n(leaked stack address from one syscall as a target during next syscall)\n\nThe main idea is that since the stack offset is randomized on each system\ncall, it is harder for an attack to reliably land in any particular place\non the thread stack, even with address exposures, as the stack base will\nchange on the next syscall. Also, since randomization is performed after\nplacing pt_regs, the ptrace-based approach[1] to discover the randomized\noffset during a long-running syscall should not be possible.\n\nDesign description:\n\nDuring most of the kernel's execution, it runs on the \"thread stack\",\nwhich is pretty deterministic in its structure: it is fixed in size,\nand on every entry from userspace to kernel on a syscall the thread\nstack starts construction from an address fetched from the per-cpu\ncpu_current_top_of_stack variable. The first element to be pushed to the\nthread stack is the pt_regs struct that stores all required CPU registers\nand syscall parameters. Finally the specific syscall function is called,\nwith the stack being used as the kernel executes the resulting request.\n\nThe goal of randomize_kstack_offset feature is to add a random offset\nafter the pt_regs has been pushed to the stack and before the rest of the\nthread stack is used during the syscall processing, and to change it every\ntime a process issues a syscall. The source of randomness is currently\narchitecture-defined (but x86 is using the low byte of rdtsc()). Future\nimprovements for different entropy sources is possible, but out of scope\nfor this patch. Further more, to add more unpredictability, new offsets\nare chosen at the end of syscalls (the timing of which should be less\neasy to measure from userspace than at syscall entry time), and stored\nin a per-CPU variable, so that the life of the value does not stay\nexplicitly tied to a single task.\n\nAs suggested by Andy Lutomirski, the offset is added using alloca()\nand an empty asm() statement with an output constraint, since it avoids\nchanges to assembly syscall entry code, to the unwinder, and provides\ncorrect stack alignment as defined by the compiler.\n\nIn order to make this available by default with zero performance impact\nfor those that don't want it, it is boot-time selectable with static\nbranches. This way, if the overhead is not wanted, it can just be\nleft turned off with no performance impact.\n\nThe generated assembly for x86_64 with GCC looks like this:\n\n...\nffffffff81003977: 65 8b 05 02 ea 00 7f  mov %gs:0x7f00ea02(%rip),%eax\n\t\t\t\t\t    # 12380 <kstack_offset>\nffffffff8100397e: 25 ff 03 00 00        and $0x3ff,%eax\nffffffff81003983: 48 83 c0 0f           add $0xf,%rax\nffffffff81003987: 25 f8 07 00 00        and $0x7f8,%eax\nffffffff8100398c: 48 29 c4              sub %rax,%rsp\nffffffff8100398f: 48 8d 44 24 0f        lea 0xf(%rsp),%rax\nffffffff81003994: 48 83 e0 f0           and $0xfffffffffffffff0,%rax\n...\n\nAs a result of the above stack alignment, this patch introduces about\n5 bits of randomness after pt_regs is spilled to the thread stack on\nx86_64, and 6 bits on x86_32 (since its has 1 fewer bit required for\nstack alignment). The amount of entropy could be adjusted based on how\nmuch of the stack space we wish to trade for security.\n\nMy measure of syscall performance overhead (on x86_64):\n\nlmbench: /usr/lib/lmbench/bin/x86_64-linux-gnu/lat_syscall -N 10000 null\n    randomize_kstack_offset=y\tSimple syscall: 0.7082 microseconds\n    randomize_kstack_offset=n\tSimple syscall: 0.7016 microseconds\n\nSo, roughly 0.9% overhead growth for a no-op syscall, which is very\nmanageable. And for people that don't want this, it's off by default.\n\nThere are two gotchas with using the alloca() trick. First,\ncompilers that have Stack Clash protection (-fstack-clash-protection)\nenabled by default (e.g. Ubuntu[3]) add pagesize stack probes to\nany dynamic stack allocations. While the randomization offset is\nalways less than a page, the resulting assembly would still contain\n(unreachable!) probing routines, bloating the resulting assembly. To\navoid this, -fno-stack-clash-protection is unconditionally added to\nthe kernel Makefile since this is the only dynamic stack allocation in\nthe kernel (now that VLAs have been removed) and it is provably safe\nfrom Stack Clash style attacks.\n\nThe second gotcha with alloca() is a negative interaction with\n-fstack-protector*, in that it sees the alloca() as an array allocation,\nwhich triggers the unconditional addition of the stack canary function\npre/post-amble which slows down syscalls regardless of the static\nbranch. In order to avoid adding this unneeded check and its associated\nperformance impact, architectures need to carefully remove uses of\n-fstack-protector-strong (or -fstack-protector) in the compilation units\nthat use the add_random_kstack() macro and to audit the resulting stack\nmitigation coverage (to make sure no desired coverage disappears). No\nchange is visible for this on x86 because the stack protector is already\nunconditionally disabled for the compilation unit, but the change is\nrequired on arm64. There is, unfortunately, no attribute that can be\nused to disable stack protector for specific functions.\n\nComparison to PaX RANDKSTACK feature:\n\nThe RANDKSTACK feature randomizes the location of the stack start\n(cpu_current_top_of_stack), i.e. including the location of pt_regs\nstructure itself on the stack. Initially this patch followed the same\napproach, but during the recent discussions[2], it has been determined\nto be of a little value since, if ptrace functionality is available for\nan attacker, they can use PTRACE_PEEKUSR/PTRACE_POKEUSR to read/write\ndifferent offsets in the pt_regs struct, observe the cache behavior of\nthe pt_regs accesses, and figure out the random stack offset. Another\ndifference is that the random offset is stored in a per-cpu variable,\nrather than having it be per-thread. As a result, these implementations\ndiffer a fair bit in their implementation details and results, though\nobviously the intent is similar.\n\n[1] https://lore.kernel.org/kernel-hardening/2236FBA76BA1254E88B949DDB74E612BA4BC57C1@IRSMSX102.ger.corp.intel.com/\n[2] https://lore.kernel.org/kernel-hardening/20190329081358.30497-1-elena.reshetova@intel.com/\n[3] https://lists.ubuntu.com/archives/ubuntu-devel/2019-June/040741.html\n\nCo-developed-by: Elena Reshetova <elena.reshetova@intel.com>\nSigned-off-by: Elena Reshetova <elena.reshetova@intel.com>\nSigned-off-by: Kees Cook <keescook@chromium.org>\nSigned-off-by: Thomas Gleixner <tglx@linutronix.de>\nReviewed-by: Thomas Gleixner <tglx@linutronix.de>\nLink: https://lore.kernel.org/r/20210401232347.2791257-4-keescook@chromium.org",
  "full_message": "stack: Optionally randomize kernel stack offset each syscall\n\nThis provides the ability for architectures to enable kernel stack base\naddress offset randomization. This feature is controlled by the boot\nparam \"randomize_kstack_offset=on/off\", with its default value set by\nCONFIG_RANDOMIZE_KSTACK_OFFSET_DEFAULT.\n\nThis feature is based on the original idea from the last public release\nof PaX's RANDKSTACK feature: https://pax.grsecurity.net/docs/randkstack.txt\nAll the credit for the original idea goes to the PaX team. Note that\nthe design and implementation of this upstream randomize_kstack_offset\nfeature differs greatly from the RANDKSTACK feature (see below).\n\nReasoning for the feature:\n\nThis feature aims to make harder the various stack-based attacks that\nrely on deterministic stack structure. We have had many such attacks in\npast (just to name few):\n\nhttps://jon.oberheide.org/files/infiltrate12-thestackisback.pdf\nhttps://jon.oberheide.org/files/stackjacking-infiltrate11.pdf\nhttps://googleprojectzero.blogspot.com/2016/06/exploiting-recursion-in-linux-kernel_20.html\n\nAs Linux kernel stack protections have been constantly improving\n(vmap-based stack allocation with guard pages, removal of thread_info,\nSTACKLEAK), attackers have had to find new ways for their exploits\nto work. They have done so, continuing to rely on the kernel's stack\ndeterminism, in situations where VMAP_STACK and THREAD_INFO_IN_TASK_STRUCT\nwere not relevant. For example, the following recent attacks would have\nbeen hampered if the stack offset was non-deterministic between syscalls:\n\nhttps://repositorio-aberto.up.pt/bitstream/10216/125357/2/374717.pdf\n(page 70: targeting the pt_regs copy with linear stack overflow)\n\nhttps://a13xp0p0v.github.io/2020/02/15/CVE-2019-18683.html\n(leaked stack address from one syscall as a target during next syscall)\n\nThe main idea is that since the stack offset is randomized on each system\ncall, it is harder for an attack to reliably land in any particular place\non the thread stack, even with address exposures, as the stack base will\nchange on the next syscall. Also, since randomization is performed after\nplacing pt_regs, the ptrace-based approach[1] to discover the randomized\noffset during a long-running syscall should not be possible.\n\nDesign description:\n\nDuring most of the kernel's execution, it runs on the \"thread stack\",\nwhich is pretty deterministic in its structure: it is fixed in size,\nand on every entry from userspace to kernel on a syscall the thread\nstack starts construction from an address fetched from the per-cpu\ncpu_current_top_of_stack variable. The first element to be pushed to the\nthread stack is the pt_regs struct that stores all required CPU registers\nand syscall parameters. Finally the specific syscall function is called,\nwith the stack being used as the kernel executes the resulting request.\n\nThe goal of randomize_kstack_offset feature is to add a random offset\nafter the pt_regs has been pushed to the stack and before the rest of the\nthread stack is used during the syscall processing, and to change it every\ntime a process issues a syscall. The source of randomness is currently\narchitecture-defined (but x86 is using the low byte of rdtsc()). Future\nimprovements for different entropy sources is possible, but out of scope\nfor this patch. Further more, to add more unpredictability, new offsets\nare chosen at the end of syscalls (the timing of which should be less\neasy to measure from userspace than at syscall entry time), and stored\nin a per-CPU variable, so that the life of the value does not stay\nexplicitly tied to a single task.\n\nAs suggested by Andy Lutomirski, the offset is added using alloca()\nand an empty asm() statement with an output constraint, since it avoids\nchanges to assembly syscall entry code, to the unwinder, and provides\ncorrect stack alignment as defined by the compiler.\n\nIn order to make this available by default with zero performance impact\nfor those that don't want it, it is boot-time selectable with static\nbranches. This way, if the overhead is not wanted, it can just be\nleft turned off with no performance impact.\n\nThe generated assembly for x86_64 with GCC looks like this:\n\n...\nffffffff81003977: 65 8b 05 02 ea 00 7f  mov %gs:0x7f00ea02(%rip),%eax\n\t\t\t\t\t    # 12380 <kstack_offset>\nffffffff8100397e: 25 ff 03 00 00        and $0x3ff,%eax\nffffffff81003983: 48 83 c0 0f           add $0xf,%rax\nffffffff81003987: 25 f8 07 00 00        and $0x7f8,%eax\nffffffff8100398c: 48 29 c4              sub %rax,%rsp\nffffffff8100398f: 48 8d 44 24 0f        lea 0xf(%rsp),%rax\nffffffff81003994: 48 83 e0 f0           and $0xfffffffffffffff0,%rax\n...\n\nAs a result of the above stack alignment, this patch introduces about\n5 bits of randomness after pt_regs is spilled to the thread stack on\nx86_64, and 6 bits on x86_32 (since its has 1 fewer bit required for\nstack alignment). The amount of entropy could be adjusted based on how\nmuch of the stack space we wish to trade for security.\n\nMy measure of syscall performance overhead (on x86_64):\n\nlmbench: /usr/lib/lmbench/bin/x86_64-linux-gnu/lat_syscall -N 10000 null\n    randomize_kstack_offset=y\tSimple syscall: 0.7082 microseconds\n    randomize_kstack_offset=n\tSimple syscall: 0.7016 microseconds\n\nSo, roughly 0.9% overhead growth for a no-op syscall, which is very\nmanageable. And for people that don't want this, it's off by default.\n\nThere are two gotchas with using the alloca() trick. First,\ncompilers that have Stack Clash protection (-fstack-clash-protection)\nenabled by default (e.g. Ubuntu[3]) add pagesize stack probes to\nany dynamic stack allocations. While the randomization offset is\nalways less than a page, the resulting assembly would still contain\n(unreachable!) probing routines, bloating the resulting assembly. To\navoid this, -fno-stack-clash-protection is unconditionally added to\nthe kernel Makefile since this is the only dynamic stack allocation in\nthe kernel (now that VLAs have been removed) and it is provably safe\nfrom Stack Clash style attacks.\n\nThe second gotcha with alloca() is a negative interaction with\n-fstack-protector*, in that it sees the alloca() as an array allocation,\nwhich triggers the unconditional addition of the stack canary function\npre/post-amble which slows down syscalls regardless of the static\nbranch. In order to avoid adding this unneeded check and its associated\nperformance impact, architectures need to carefully remove uses of\n-fstack-protector-strong (or -fstack-protector) in the compilation units\nthat use the add_random_kstack() macro and to audit the resulting stack\nmitigation coverage (to make sure no desired coverage disappears). No\nchange is visible for this on x86 because the stack protector is already\nunconditionally disabled for the compilation unit, but the change is\nrequired on arm64. There is, unfortunately, no attribute that can be\nused to disable stack protector for specific functions.\n\nComparison to PaX RANDKSTACK feature:\n\nThe RANDKSTACK feature randomizes the location of the stack start\n(cpu_current_top_of_stack), i.e. including the location of pt_regs\nstructure itself on the stack. Initially this patch followed the same\napproach, but during the recent discussions[2], it has been determined\nto be of a little value since, if ptrace functionality is available for\nan attacker, they can use PTRACE_PEEKUSR/PTRACE_POKEUSR to read/write\ndifferent offsets in the pt_regs struct, observe the cache behavior of\nthe pt_regs accesses, and figure out the random stack offset. Another\ndifference is that the random offset is stored in a per-cpu variable,\nrather than having it be per-thread. As a result, these implementations\ndiffer a fair bit in their implementation details and results, though\nobviously the intent is similar.\n\n[1] https://lore.kernel.org/kernel-hardening/2236FBA76BA1254E88B949DDB74E612BA4BC57C1@IRSMSX102.ger.corp.intel.com/\n[2] https://lore.kernel.org/kernel-hardening/20190329081358.30497-1-elena.reshetova@intel.com/\n[3] https://lists.ubuntu.com/archives/ubuntu-devel/2019-June/040741.html\n\nCo-developed-by: Elena Reshetova <elena.reshetova@intel.com>\nSigned-off-by: Elena Reshetova <elena.reshetova@intel.com>\nSigned-off-by: Kees Cook <keescook@chromium.org>\nSigned-off-by: Thomas Gleixner <tglx@linutronix.de>\nReviewed-by: Thomas Gleixner <tglx@linutronix.de>\nLink: https://lore.kernel.org/r/20210401232347.2791257-4-keescook@chromium.org",
  "author_name": "Kees Cook",
  "author_email": "keescook@chromium.org",
  "author_date": "Thu Apr 1 16:23:44 2021 -0700",
  "author_date_iso": "2021-04-01T16:23:44-07:00",
  "committer_name": "Thomas Gleixner",
  "committer_email": "tglx@linutronix.de",
  "committer_date": "Thu Apr 8 14:05:19 2021 +0200",
  "committer_date_iso": "2021-04-08T14:05:19+02:00",
  "files_changed": [
    "Documentation/admin-guide/kernel-parameters.txt",
    "Makefile",
    "arch/Kconfig",
    "include/linux/randomize_kstack.h",
    "init/main.c"
  ],
  "files_changed_count": 5,
  "stats": [
    {
      "file": "Documentation/admin-guide/kernel-parameters.txt",
      "insertions": 11,
      "deletions": 0
    },
    {
      "file": "Makefile",
      "insertions": 4,
      "deletions": 0
    },
    {
      "file": "arch/Kconfig",
      "insertions": 23,
      "deletions": 0
    },
    {
      "file": "include/linux/randomize_kstack.h",
      "insertions": 54,
      "deletions": 0
    },
    {
      "file": "init/main.c",
      "insertions": 23,
      "deletions": 0
    }
  ],
  "total_insertions": 115,
  "total_deletions": 0,
  "total_changes": 115,
  "parents": [
    "51cba1ebc60df9c4ce034a9f5441169c0d0956c0"
  ],
  "branches": [
    "* development",
    "remotes/origin/HEAD -> origin/master",
    "remotes/origin/master"
  ],
  "tags": [],
  "is_merge": false,
  "security_info": {
    "cve_ids": [
      "CVE-2019-18683"
    ],
    "security_keywords": [
      "hardening"
    ]
  },
  "fix_type": "cve",
  "file_results": [
    {
      "file": "Documentation/admin-guide/kernel-parameters.txt",
      "pre_version": false,
      "post_version": true,
      "patch": true
    },
    {
      "file": "Makefile",
      "pre_version": false,
      "post_version": true,
      "patch": true
    },
    {
      "file": "arch/Kconfig",
      "pre_version": false,
      "post_version": true,
      "patch": true
    },
    {
      "file": "include/linux/randomize_kstack.h",
      "pre_version": false,
      "post_version": true,
      "patch": true
    },
    {
      "file": "init/main.c",
      "pre_version": false,
      "post_version": true,
      "patch": true
    }
  ]
}