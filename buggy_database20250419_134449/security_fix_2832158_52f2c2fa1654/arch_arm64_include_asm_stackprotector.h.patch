commit 28321582334c261c13b20d7efe634e610b4c100b
Author: Amit Daniel Kachhap <amit.kachhap@arm.com>
Date:   Fri Mar 13 14:34:57 2020 +0530

    arm64: initialize ptrauth keys for kernel booting task
    
    This patch uses the existing boot_init_stack_canary arch function
    to initialize the ptrauth keys for the booting task in the primary
    core. The requirement here is that it should be always inline and
    the caller must never return.
    
    As pointer authentication too detects a subset of stack corruption
    so it makes sense to place this code here.
    
    Both pointer authentication and stack canary codes are protected
    by their respective config option.
    
    Suggested-by: Ard Biesheuvel <ardb@kernel.org>
    Signed-off-by: Amit Daniel Kachhap <amit.kachhap@arm.com>
    Reviewed-by: Vincenzo Frascino <Vincenzo.Frascino@arm.com>
    Reviewed-by: Catalin Marinas <catalin.marinas@arm.com>
    Signed-off-by: Catalin Marinas <catalin.marinas@arm.com>

diff --git a/arch/arm64/include/asm/stackprotector.h b/arch/arm64/include/asm/stackprotector.h
index 5884a2b02827..7263e0bac680 100644
--- a/arch/arm64/include/asm/stackprotector.h
+++ b/arch/arm64/include/asm/stackprotector.h
@@ -15,6 +15,7 @@
 
 #include <linux/random.h>
 #include <linux/version.h>
+#include <asm/pointer_auth.h>
 
 extern unsigned long __stack_chk_guard;
 
@@ -26,6 +27,7 @@ extern unsigned long __stack_chk_guard;
  */
 static __always_inline void boot_init_stack_canary(void)
 {
+#if defined(CONFIG_STACKPROTECTOR)
 	unsigned long canary;
 
 	/* Try to get a semi random initial value. */
@@ -36,6 +38,9 @@ static __always_inline void boot_init_stack_canary(void)
 	current->stack_canary = canary;
 	if (!IS_ENABLED(CONFIG_STACKPROTECTOR_PER_TASK))
 		__stack_chk_guard = current->stack_canary;
+#endif
+	ptrauth_thread_init_kernel(current);
+	ptrauth_thread_switch_kernel(current);
 }
 
 #endif	/* _ASM_STACKPROTECTOR_H */