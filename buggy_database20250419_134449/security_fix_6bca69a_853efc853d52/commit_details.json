{
  "hash": "6bca69ada4bc20fa27eb44a5e09da3363d1752af",
  "hash_short": "6bca69ad",
  "subject": "x86/kvm: Sanitize kvm_async_pf_task_wait()",
  "body": "While working on the entry consolidation I stumbled over the KVM async page\nfault handler and kvm_async_pf_task_wait() in particular. It took me a\nwhile to realize that the randomly sprinkled around rcu_irq_enter()/exit()\ninvocations are just cargo cult programming. Several patches \"fixed\" RCU\nsplats by curing the symptoms without noticing that the code is flawed \nfrom a design perspective.\n\nThe main problem is that this async injection is not based on a proper\nhandshake mechanism and only respects the minimal requirement, i.e. the\nguest is not in a state where it has interrupts disabled.\n\nAside of that the actual code is a convoluted one fits it all swiss army\nknife. It is invoked from different places with different RCU constraints:\n\n  1) Host side:\n\n     vcpu_enter_guest()\n       kvm_x86_ops->handle_exit()\n         kvm_handle_page_fault()\n           kvm_async_pf_task_wait()\n\n     The invocation happens from fully preemptible context.\n\n  2) Guest side:\n\n     The async page fault interrupted:\n\n         a) user space\n\n\t b) preemptible kernel code which is not in a RCU read side\n\t    critical section\n\n     \t c) non-preemtible kernel code or a RCU read side critical section\n\t    or kernel code with CONFIG_PREEMPTION=n which allows not to\n\t    differentiate between #2b and #2c.\n\nRCU is watching for:\n\n  #1  The vCPU exited and current is definitely not the idle task\n\n  #2a The #PF entry code on the guest went through enter_from_user_mode()\n      which reactivates RCU\n\n  #2b There is no preemptible, interrupts enabled code in the kernel\n      which can run with RCU looking away. (The idle task is always\n      non preemptible).\n\nI.e. all schedulable states (#1, #2a, #2b) do not need any of this RCU\nvoodoo at all.\n\nIn #2c RCU is eventually not watching, but as that state cannot schedule\nanyway there is no point to worry about it so it has to invoke\nrcu_irq_enter() before running that code. This can be optimized, but this\nwill be done as an extra step in course of the entry code consolidation\nwork.\n\nSo the proper solution for this is to:\n\n  - Split kvm_async_pf_task_wait() into schedule and halt based waiting\n    interfaces which share the enqueueing code.\n\n  - Add comments (condensed form of this changelog) to spare others the\n    time waste and pain of reverse engineering all of this with the help of\n    uncomprehensible changelogs and code history.\n\n  - Invoke kvm_async_pf_task_wait_schedule() from kvm_handle_page_fault(),\n    user mode and schedulable kernel side async page faults (#1, #2a, #2b)\n\n  - Invoke kvm_async_pf_task_wait_halt() for the non schedulable kernel\n    case (#2c).\n\n    For this case also remove the rcu_irq_exit()/enter() pair around the\n    halt as it is just a pointless exercise:\n\n       - vCPUs can VMEXIT at any random point and can be scheduled out for\n         an arbitrary amount of time by the host and this is not any\n         different except that it voluntary triggers the exit via halt.\n\n       - The interrupted context could have RCU watching already. So the\n\t rcu_irq_exit() before the halt is not gaining anything aside of\n\t confusing the reader. Claiming that this might prevent RCU stalls\n\t is just an illusion.\n\nSigned-off-by: Thomas Gleixner <tglx@linutronix.de>\nReviewed-by: Alexandre Chartre <alexandre.chartre@oracle.com>\nAcked-by: Paolo Bonzini <pbonzini@redhat.com>\nAcked-by: Peter Zijlstra <peterz@infradead.org>\nLink: https://lkml.kernel.org/r/20200505134059.262701431@linutronix.de",
  "full_message": "x86/kvm: Sanitize kvm_async_pf_task_wait()\n\nWhile working on the entry consolidation I stumbled over the KVM async page\nfault handler and kvm_async_pf_task_wait() in particular. It took me a\nwhile to realize that the randomly sprinkled around rcu_irq_enter()/exit()\ninvocations are just cargo cult programming. Several patches \"fixed\" RCU\nsplats by curing the symptoms without noticing that the code is flawed \nfrom a design perspective.\n\nThe main problem is that this async injection is not based on a proper\nhandshake mechanism and only respects the minimal requirement, i.e. the\nguest is not in a state where it has interrupts disabled.\n\nAside of that the actual code is a convoluted one fits it all swiss army\nknife. It is invoked from different places with different RCU constraints:\n\n  1) Host side:\n\n     vcpu_enter_guest()\n       kvm_x86_ops->handle_exit()\n         kvm_handle_page_fault()\n           kvm_async_pf_task_wait()\n\n     The invocation happens from fully preemptible context.\n\n  2) Guest side:\n\n     The async page fault interrupted:\n\n         a) user space\n\n\t b) preemptible kernel code which is not in a RCU read side\n\t    critical section\n\n     \t c) non-preemtible kernel code or a RCU read side critical section\n\t    or kernel code with CONFIG_PREEMPTION=n which allows not to\n\t    differentiate between #2b and #2c.\n\nRCU is watching for:\n\n  #1  The vCPU exited and current is definitely not the idle task\n\n  #2a The #PF entry code on the guest went through enter_from_user_mode()\n      which reactivates RCU\n\n  #2b There is no preemptible, interrupts enabled code in the kernel\n      which can run with RCU looking away. (The idle task is always\n      non preemptible).\n\nI.e. all schedulable states (#1, #2a, #2b) do not need any of this RCU\nvoodoo at all.\n\nIn #2c RCU is eventually not watching, but as that state cannot schedule\nanyway there is no point to worry about it so it has to invoke\nrcu_irq_enter() before running that code. This can be optimized, but this\nwill be done as an extra step in course of the entry code consolidation\nwork.\n\nSo the proper solution for this is to:\n\n  - Split kvm_async_pf_task_wait() into schedule and halt based waiting\n    interfaces which share the enqueueing code.\n\n  - Add comments (condensed form of this changelog) to spare others the\n    time waste and pain of reverse engineering all of this with the help of\n    uncomprehensible changelogs and code history.\n\n  - Invoke kvm_async_pf_task_wait_schedule() from kvm_handle_page_fault(),\n    user mode and schedulable kernel side async page faults (#1, #2a, #2b)\n\n  - Invoke kvm_async_pf_task_wait_halt() for the non schedulable kernel\n    case (#2c).\n\n    For this case also remove the rcu_irq_exit()/enter() pair around the\n    halt as it is just a pointless exercise:\n\n       - vCPUs can VMEXIT at any random point and can be scheduled out for\n         an arbitrary amount of time by the host and this is not any\n         different except that it voluntary triggers the exit via halt.\n\n       - The interrupted context could have RCU watching already. So the\n\t rcu_irq_exit() before the halt is not gaining anything aside of\n\t confusing the reader. Claiming that this might prevent RCU stalls\n\t is just an illusion.\n\nSigned-off-by: Thomas Gleixner <tglx@linutronix.de>\nReviewed-by: Alexandre Chartre <alexandre.chartre@oracle.com>\nAcked-by: Paolo Bonzini <pbonzini@redhat.com>\nAcked-by: Peter Zijlstra <peterz@infradead.org>\nLink: https://lkml.kernel.org/r/20200505134059.262701431@linutronix.de",
  "author_name": "Thomas Gleixner",
  "author_email": "tglx@linutronix.de",
  "author_date": "Sat Mar 7 00:42:06 2020 +0100",
  "author_date_iso": "2020-03-07T00:42:06+01:00",
  "committer_name": "Thomas Gleixner",
  "committer_email": "tglx@linutronix.de",
  "committer_date": "Tue May 19 15:53:58 2020 +0200",
  "committer_date_iso": "2020-05-19T15:53:58+02:00",
  "files_changed": [
    "arch/x86/include/asm/kvm_para.h",
    "arch/x86/kernel/kvm.c",
    "arch/x86/kvm/mmu/mmu.c"
  ],
  "files_changed_count": 3,
  "stats": [
    {
      "file": "arch/x86/include/asm/kvm_para.h",
      "insertions": 2,
      "deletions": 2
    },
    {
      "file": "arch/x86/kernel/kvm.c",
      "insertions": 141,
      "deletions": 60
    },
    {
      "file": "arch/x86/kvm/mmu/mmu.c",
      "insertions": 1,
      "deletions": 1
    }
  ],
  "total_insertions": 144,
  "total_deletions": 63,
  "total_changes": 207,
  "parents": [
    "ef68017eb5704eb2b0577c3aa6619e13caf2b59f"
  ],
  "branches": [
    "* development",
    "remotes/origin/HEAD -> origin/master",
    "remotes/origin/master"
  ],
  "tags": [],
  "is_merge": false,
  "security_info": {
    "cve_ids": [],
    "security_keywords": [
      "Sanitize",
      "injection"
    ]
  },
  "fix_type": "security",
  "file_results": [
    {
      "file": "arch/x86/include/asm/kvm_para.h",
      "pre_version": true,
      "post_version": true,
      "patch": true
    },
    {
      "file": "arch/x86/kernel/kvm.c",
      "pre_version": true,
      "post_version": true,
      "patch": true
    },
    {
      "file": "arch/x86/kvm/mmu/mmu.c",
      "pre_version": false,
      "post_version": true,
      "patch": true
    }
  ]
}