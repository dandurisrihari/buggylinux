commit d4c56f97ff21df405d0cebe11f49e3c3c79662b5
Author: Dan Williams <dan.j.williams@intel.com>
Date:   Sat Feb 2 19:49:58 2008 -0700

    async_tx: replace 'int_en' with operation preparation flags
    
    Pass a full set of flags to drivers' per-operation 'prep' routines.
    Currently the only flag passed is DMA_PREP_INTERRUPT.  The expectation is
    that arch-specific async_tx_find_channel() implementations can exploit this
    capability to find the best channel for an operation.
    
    Signed-off-by: Dan Williams <dan.j.williams@intel.com>
    Acked-by: Shannon Nelson <shannon.nelson@intel.com>
    Reviewed-by: Haavard Skinnemoen <hskinnemoen@atmel.com>

diff --git a/crypto/async_tx/async_xor.c b/crypto/async_tx/async_xor.c
index 12cba1a4205b..68d2fe4465d8 100644
--- a/crypto/async_tx/async_xor.c
+++ b/crypto/async_tx/async_xor.c
@@ -45,6 +45,7 @@ do_async_xor(struct dma_device *device,
 	dma_addr_t *dma_src = (dma_addr_t *) src_list;
 	struct dma_async_tx_descriptor *tx;
 	int i;
+	unsigned long dma_prep_flags = cb_fn ? DMA_PREP_INTERRUPT : 0;
 
 	pr_debug("%s: len: %zu\n", __FUNCTION__, len);
 
@@ -60,7 +61,7 @@ do_async_xor(struct dma_device *device,
 	 * in case they can not provide a descriptor
 	 */
 	tx = device->device_prep_dma_xor(chan, dma_dest, dma_src, src_cnt, len,
-					 cb_fn != NULL);
+					 dma_prep_flags);
 	if (!tx) {
 		if (depend_tx)
 			dma_wait_for_async_tx(depend_tx);
@@ -68,7 +69,7 @@ do_async_xor(struct dma_device *device,
 		while (!tx)
 			tx = device->device_prep_dma_xor(chan, dma_dest,
 							 dma_src, src_cnt, len,
-							 cb_fn != NULL);
+							 dma_prep_flags);
 	}
 
 	async_tx_submit(chan, tx, flags, depend_tx, cb_fn, cb_param);
@@ -268,6 +269,7 @@ async_xor_zero_sum(struct page *dest, struct page **src_list,
 
 	if (device) {
 		dma_addr_t *dma_src = (dma_addr_t *) src_list;
+		unsigned long dma_prep_flags = cb_fn ? DMA_PREP_INTERRUPT : 0;
 		int i;
 
 		pr_debug("%s: (async) len: %zu\n", __FUNCTION__, len);
@@ -278,7 +280,7 @@ async_xor_zero_sum(struct page *dest, struct page **src_list,
 
 		tx = device->device_prep_dma_zero_sum(chan, dma_src, src_cnt,
 						      len, result,
-						      cb_fn != NULL);
+						      dma_prep_flags);
 		if (!tx) {
 			if (depend_tx)
 				dma_wait_for_async_tx(depend_tx);
@@ -286,7 +288,7 @@ async_xor_zero_sum(struct page *dest, struct page **src_list,
 			while (!tx)
 				tx = device->device_prep_dma_zero_sum(chan,
 					dma_src, src_cnt, len, result,
-					cb_fn != NULL);
+					dma_prep_flags);
 		}
 
 		async_tx_submit(chan, tx, flags, depend_tx, cb_fn, cb_param);