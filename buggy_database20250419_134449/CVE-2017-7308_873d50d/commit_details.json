{
  "hash": "873d50d58f67ef15d2777b5e7f7a5268bb1fbae2",
  "hash_short": "873d50d5",
  "subject": "x86/asm: Pin sensitive CR4 bits",
  "body": "Several recent exploits have used direct calls to the native_write_cr4()\nfunction to disable SMEP and SMAP before then continuing their exploits\nusing userspace memory access.\n\nDirect calls of this form can be mitigate by pinning bits of CR4 so that\nthey cannot be changed through a common function. This is not intended to\nbe a general ROP protection (which would require CFI to defend against\nproperly), but rather a way to avoid trivial direct function calling (or\nCFI bypasses via a matching function prototype) as seen in:\n\nhttps://googleprojectzero.blogspot.com/2017/05/exploiting-linux-kernel-via-packet.html\n(https://github.com/xairy/kernel-exploits/tree/master/CVE-2017-7308)\n\nThe goals of this change:\n\n - Pin specific bits (SMEP, SMAP, and UMIP) when writing CR4.\n\n - Avoid setting the bits too early (they must become pinned only after\n   CPU feature detection and selection has finished).\n\n - Pinning mask needs to be read-only during normal runtime.\n\n - Pinning needs to be checked after write to validate the cr4 state\n\nUsing __ro_after_init on the mask is done so it can't be first disabled\nwith a malicious write.\n\nSince these bits are global state (once established by the boot CPU and\nkernel boot parameters), they are safe to write to secondary CPUs before\nthose CPUs have finished feature detection. As such, the bits are set at\nthe first cr4 write, so that cr4 write bugs can be detected (instead of\nsilently papered over). This uses a few bytes less storage of a location we\ndon't have: read-only per-CPU data.\n\nA check is performed after the register write because an attack could just\nskip directly to the register write. Such a direct jump is possible because\nof how this function may be built by the compiler (especially due to the\nremoval of frame pointers) where it doesn't add a stack frame (function\nexit may only be a retq without pops) which is sufficient for trivial\nexploitation like in the timer overwrites mentioned above).\n\nThe asm argument constraints gain the \"+\" modifier to convince the compiler\nthat it shouldn't make ordering assumptions about the arguments or memory,\nand treat them as changed.\n\nSigned-off-by: Kees Cook <keescook@chromium.org>\nSigned-off-by: Thomas Gleixner <tglx@linutronix.de>\nCc: Linus Torvalds <torvalds@linux-foundation.org>\nCc: Peter Zijlstra <peterz@infradead.org>\nCc: Dave Hansen <dave.hansen@intel.com>\nCc: kernel-hardening@lists.openwall.com\nLink: https://lkml.kernel.org/r/20190618045503.39105-3-keescook@chromium.org",
  "full_message": "x86/asm: Pin sensitive CR4 bits\n\nSeveral recent exploits have used direct calls to the native_write_cr4()\nfunction to disable SMEP and SMAP before then continuing their exploits\nusing userspace memory access.\n\nDirect calls of this form can be mitigate by pinning bits of CR4 so that\nthey cannot be changed through a common function. This is not intended to\nbe a general ROP protection (which would require CFI to defend against\nproperly), but rather a way to avoid trivial direct function calling (or\nCFI bypasses via a matching function prototype) as seen in:\n\nhttps://googleprojectzero.blogspot.com/2017/05/exploiting-linux-kernel-via-packet.html\n(https://github.com/xairy/kernel-exploits/tree/master/CVE-2017-7308)\n\nThe goals of this change:\n\n - Pin specific bits (SMEP, SMAP, and UMIP) when writing CR4.\n\n - Avoid setting the bits too early (they must become pinned only after\n   CPU feature detection and selection has finished).\n\n - Pinning mask needs to be read-only during normal runtime.\n\n - Pinning needs to be checked after write to validate the cr4 state\n\nUsing __ro_after_init on the mask is done so it can't be first disabled\nwith a malicious write.\n\nSince these bits are global state (once established by the boot CPU and\nkernel boot parameters), they are safe to write to secondary CPUs before\nthose CPUs have finished feature detection. As such, the bits are set at\nthe first cr4 write, so that cr4 write bugs can be detected (instead of\nsilently papered over). This uses a few bytes less storage of a location we\ndon't have: read-only per-CPU data.\n\nA check is performed after the register write because an attack could just\nskip directly to the register write. Such a direct jump is possible because\nof how this function may be built by the compiler (especially due to the\nremoval of frame pointers) where it doesn't add a stack frame (function\nexit may only be a retq without pops) which is sufficient for trivial\nexploitation like in the timer overwrites mentioned above).\n\nThe asm argument constraints gain the \"+\" modifier to convince the compiler\nthat it shouldn't make ordering assumptions about the arguments or memory,\nand treat them as changed.\n\nSigned-off-by: Kees Cook <keescook@chromium.org>\nSigned-off-by: Thomas Gleixner <tglx@linutronix.de>\nCc: Linus Torvalds <torvalds@linux-foundation.org>\nCc: Peter Zijlstra <peterz@infradead.org>\nCc: Dave Hansen <dave.hansen@intel.com>\nCc: kernel-hardening@lists.openwall.com\nLink: https://lkml.kernel.org/r/20190618045503.39105-3-keescook@chromium.org",
  "author_name": "Kees Cook",
  "author_email": "keescook@chromium.org",
  "author_date": "Mon Jun 17 21:55:02 2019 -0700",
  "author_date_iso": "2019-06-17T21:55:02-07:00",
  "committer_name": "Thomas Gleixner",
  "committer_email": "tglx@linutronix.de",
  "committer_date": "Sat Jun 22 11:55:22 2019 +0200",
  "committer_date_iso": "2019-06-22T11:55:22+02:00",
  "files_changed": [
    "arch/x86/include/asm/special_insns.h",
    "arch/x86/kernel/cpu/common.c",
    "arch/x86/kernel/smpboot.c"
  ],
  "files_changed_count": 3,
  "stats": [
    {
      "file": "arch/x86/include/asm/special_insns.h",
      "insertions": 21,
      "deletions": 1
    },
    {
      "file": "arch/x86/kernel/cpu/common.c",
      "insertions": 20,
      "deletions": 0
    },
    {
      "file": "arch/x86/kernel/smpboot.c",
      "insertions": 7,
      "deletions": 1
    }
  ],
  "total_insertions": 48,
  "total_deletions": 2,
  "total_changes": 50,
  "parents": [
    "7b347ad4938ddca1a22b983e36b9ef825a72d230"
  ],
  "branches": [
    "* development",
    "master",
    "remotes/origin/HEAD -> origin/master",
    "remotes/origin/master"
  ],
  "tags": [
    "v5.3",
    "v5.3-rc1",
    "v5.3-rc2",
    "v5.3-rc3",
    "v5.3-rc4",
    "v5.3-rc5",
    "v5.3-rc6",
    "v5.3-rc7",
    "v5.3-rc8",
    "v5.4"
  ],
  "is_merge": false,
  "security_info": {
    "cve_ids": [
      "CVE-2017-7308"
    ],
    "security_keywords": [
      "hardening"
    ]
  },
  "fix_type": "cve",
  "file_results": [
    {
      "file": "arch/x86/include/asm/special_insns.h",
      "pre_version": false,
      "post_version": true,
      "patch": true
    },
    {
      "file": "arch/x86/kernel/cpu/common.c",
      "pre_version": false,
      "post_version": true,
      "patch": true
    },
    {
      "file": "arch/x86/kernel/smpboot.c",
      "pre_version": false,
      "post_version": true,
      "patch": true
    }
  ]
}