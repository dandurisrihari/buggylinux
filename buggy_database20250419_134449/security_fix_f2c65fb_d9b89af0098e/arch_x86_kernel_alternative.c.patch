commit f2c65fb3221adc6b73b0549fc7ba892022db9797
Author: Nadav Amit <nadav.amit@gmail.com>
Date:   Thu Apr 25 17:11:31 2019 -0700

    x86/modules: Avoid breaking W^X while loading modules
    
    When modules and BPF filters are loaded, there is a time window in
    which some memory is both writable and executable. An attacker that has
    already found another vulnerability (e.g., a dangling pointer) might be
    able to exploit this behavior to overwrite kernel code. Prevent having
    writable executable PTEs in this stage.
    
    In addition, avoiding having W+X mappings can also slightly simplify the
    patching of modules code on initialization (e.g., by alternatives and
    static-key), as would be done in the next patch. This was actually the
    main motivation for this patch.
    
    To avoid having W+X mappings, set them initially as RW (NX) and after
    they are set as RO set them as X as well. Setting them as executable is
    done as a separate step to avoid one core in which the old PTE is cached
    (hence writable), and another which sees the updated PTE (executable),
    which would break the W^X protection.
    
    Suggested-by: Thomas Gleixner <tglx@linutronix.de>
    Suggested-by: Andy Lutomirski <luto@amacapital.net>
    Signed-off-by: Nadav Amit <namit@vmware.com>
    Signed-off-by: Rick Edgecombe <rick.p.edgecombe@intel.com>
    Signed-off-by: Peter Zijlstra (Intel) <peterz@infradead.org>
    Cc: <akpm@linux-foundation.org>
    Cc: <ard.biesheuvel@linaro.org>
    Cc: <deneen.t.dock@intel.com>
    Cc: <kernel-hardening@lists.openwall.com>
    Cc: <kristen@linux.intel.com>
    Cc: <linux_dti@icloud.com>
    Cc: <will.deacon@arm.com>
    Cc: Andy Lutomirski <luto@kernel.org>
    Cc: Borislav Petkov <bp@alien8.de>
    Cc: Dave Hansen <dave.hansen@intel.com>
    Cc: H. Peter Anvin <hpa@zytor.com>
    Cc: Jessica Yu <jeyu@kernel.org>
    Cc: Kees Cook <keescook@chromium.org>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Masami Hiramatsu <mhiramat@kernel.org>
    Cc: Rik van Riel <riel@surriel.com>
    Link: https://lkml.kernel.org/r/20190426001143.4983-12-namit@vmware.com
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/x86/kernel/alternative.c b/arch/x86/kernel/alternative.c
index 599203876c32..3d2b6b6fb20c 100644
--- a/arch/x86/kernel/alternative.c
+++ b/arch/x86/kernel/alternative.c
@@ -668,15 +668,29 @@ void __init alternative_instructions(void)
  * handlers seeing an inconsistent instruction while you patch.
  */
 void *__init_or_module text_poke_early(void *addr, const void *opcode,
-					      size_t len)
+				       size_t len)
 {
 	unsigned long flags;
-	local_irq_save(flags);
-	memcpy(addr, opcode, len);
-	local_irq_restore(flags);
-	sync_core();
-	/* Could also do a CLFLUSH here to speed up CPU recovery; but
-	   that causes hangs on some VIA CPUs. */
+
+	if (boot_cpu_has(X86_FEATURE_NX) &&
+	    is_module_text_address((unsigned long)addr)) {
+		/*
+		 * Modules text is marked initially as non-executable, so the
+		 * code cannot be running and speculative code-fetches are
+		 * prevented. Just change the code.
+		 */
+		memcpy(addr, opcode, len);
+	} else {
+		local_irq_save(flags);
+		memcpy(addr, opcode, len);
+		local_irq_restore(flags);
+		sync_core();
+
+		/*
+		 * Could also do a CLFLUSH here to speed up CPU recovery; but
+		 * that causes hangs on some VIA CPUs.
+		 */
+	}
 	return addr;
 }