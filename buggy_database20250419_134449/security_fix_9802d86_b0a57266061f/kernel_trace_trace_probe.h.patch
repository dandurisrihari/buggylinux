commit 9802d86585db91655c7d1929a4f6bbe0952ea88e
Author: Josef Bacik <jbacik@fb.com>
Date:   Mon Dec 11 11:36:48 2017 -0500

    bpf: add a bpf_override_function helper
    
    Error injection is sloppy and very ad-hoc.  BPF could fill this niche
    perfectly with it's kprobe functionality.  We could make sure errors are
    only triggered in specific call chains that we care about with very
    specific situations.  Accomplish this with the bpf_override_funciton
    helper.  This will modify the probe'd callers return value to the
    specified value and set the PC to an override function that simply
    returns, bypassing the originally probed function.  This gives us a nice
    clean way to implement systematic error injection for all of our code
    paths.
    
    Acked-by: Alexei Starovoitov <ast@kernel.org>
    Acked-by: Ingo Molnar <mingo@kernel.org>
    Signed-off-by: Josef Bacik <jbacik@fb.com>
    Signed-off-by: Alexei Starovoitov <ast@kernel.org>

diff --git a/kernel/trace/trace_probe.h b/kernel/trace/trace_probe.h
index fb66e3eaa192..5e54d748c84c 100644
--- a/kernel/trace/trace_probe.h
+++ b/kernel/trace/trace_probe.h
@@ -252,6 +252,8 @@ struct symbol_cache;
 unsigned long update_symbol_cache(struct symbol_cache *sc);
 void free_symbol_cache(struct symbol_cache *sc);
 struct symbol_cache *alloc_symbol_cache(const char *sym, long offset);
+int trace_kprobe_ftrace(struct trace_event_call *call);
+int trace_kprobe_error_injectable(struct trace_event_call *call);
 #else
 /* uprobes do not support symbol fetch methods */
 #define fetch_symbol_u8			NULL
@@ -277,6 +279,16 @@ alloc_symbol_cache(const char *sym, long offset)
 {
 	return NULL;
 }
+
+static inline int trace_kprobe_ftrace(struct trace_event_call *call)
+{
+	return 0;
+}
+
+static inline int trace_kprobe_error_injectable(struct trace_event_call *call)
+{
+	return 0;
+}
 #endif /* CONFIG_KPROBE_EVENTS */
 
 struct probe_arg {