commit fb53ac6cd0269987b1b77f957db453b3ec7bf7e4
Author: Paolo Valente <paolo.valente@linaro.org>
Date:   Tue Mar 12 09:59:28 2019 +0100

    block, bfq: do not idle for lowest-weight queues
    
    In most cases, it is detrimental for throughput to plug I/O dispatch
    when the in-service bfq_queue becomes temporarily empty (plugging is
    performed to wait for the possible arrival, soon, of new I/O from the
    in-service queue). There is however a case where plugging is needed
    for service guarantees. If a bfq_queue, say Q, has a higher weight
    than some other active bfq_queue, and is sync, i.e., contains sync
    I/O, then, to guarantee that Q does receive a higher share of the
    throughput than other lower-weight queues, it is necessary to plug I/O
    dispatch when Q remains temporarily empty while being served.
    
    For this reason, BFQ performs I/O plugging when some active bfq_queue
    has a higher weight than some other active bfq_queue. But this is
    unnecessarily overkill. In fact, if the in-service bfq_queue actually
    has a weight lower than or equal to the other queues, then the queue
    *must not* be guaranteed a higher share of the throughput than the
    other queues. So, not plugging I/O cannot cause any harm to the
    queue. And can boost throughput.
    
    Taking advantage of this fact, this commit does not plug I/O for sync
    bfq_queues with a weight lower than or equal to the weights of the
    other queues. Here is an example of the resulting throughput boost
    with the dbench workload, which is particularly nasty for BFQ. With
    the dbench test in the Phoronix suite, BFQ reaches its lowest total
    throughput with 6 clients on a filesystem with journaling, in case the
    journaling daemon has a higher weight than normal processes. Before
    this commit, the total throughput was ~80 MB/sec on a PLEXTOR PX-256M5,
    after this commit it is ~100 MB/sec.
    
    Tested-by: Holger Hoffst√§tte <holger@applied-asynchrony.com>
    Tested-by: Oleksandr Natalenko <oleksandr@natalenko.name>
    Signed-off-by: Paolo Valente <paolo.valente@linaro.org>
    Signed-off-by: Jens Axboe <axboe@kernel.dk>

diff --git a/block/bfq-iosched.h b/block/bfq-iosched.h
index 062e1c4787f4..81cabf51a87e 100644
--- a/block/bfq-iosched.h
+++ b/block/bfq-iosched.h
@@ -450,7 +450,7 @@ struct bfq_data {
 	 * weight-raised @bfq_queue (see the comments to the functions
 	 * bfq_weights_tree_[add|remove] for further details).
 	 */
-	struct rb_root queue_weights_tree;
+	struct rb_root_cached queue_weights_tree;
 
 	/*
 	 * Number of groups with at least one descendant process that
@@ -898,10 +898,10 @@ void bic_set_bfqq(struct bfq_io_cq *bic, struct bfq_queue *bfqq, bool is_sync);
 struct bfq_data *bic_to_bfqd(struct bfq_io_cq *bic);
 void bfq_pos_tree_add_move(struct bfq_data *bfqd, struct bfq_queue *bfqq);
 void bfq_weights_tree_add(struct bfq_data *bfqd, struct bfq_queue *bfqq,
-			  struct rb_root *root);
+			  struct rb_root_cached *root);
 void __bfq_weights_tree_remove(struct bfq_data *bfqd,
 			       struct bfq_queue *bfqq,
-			       struct rb_root *root);
+			       struct rb_root_cached *root);
 void bfq_weights_tree_remove(struct bfq_data *bfqd,
 			     struct bfq_queue *bfqq);
 void bfq_bfqq_expire(struct bfq_data *bfqd, struct bfq_queue *bfqq,