commit d0edc2473be9d70f999282e1ca7863ad6ae704dc
Author: Paolo Valente <paolo.valente@linaro.org>
Date:   Fri Sep 14 16:23:08 2018 +0200

    block, bfq: inject other-queue I/O into seeky idle queues on NCQ flash
    
    The Achilles' heel of BFQ is its failing to reach a high throughput
    with sync random I/O on flash storage with internal queueing, in case
    the processes doing I/O have differentiated weights.
    
    The cause of this failure is as follows. If at least two processes do
    sync I/O, and have a different weight from each other, then BFQ plugs
    I/O dispatching every time one of these processes, while it is being
    served, remains temporarily without pending I/O requests. This
    plugging is necessary to guarantee that every process enjoys a
    bandwidth proportional to its weight; but it empties the internal
    queue(s) of the drive. And this kills throughput with random I/O. So,
    if some processes have differentiated weights and do both sync and
    random I/O, the end result is a throughput collapse.
    
    This commit tries to counter this problem by injecting the service of
    other processes, in a controlled way, while the process in service
    happens to have no I/O. This injection is performed only if the medium
    is non rotational and performs internal queueing, and the process in
    service does random I/O (service injection might be beneficial for
    sequential I/O too, we'll work on that).
    
    As an example of the benefits of this commit, on a PLEXTOR PX-256M5S
    SSD, and with five processes having differentiated weights and doing
    sync random 4KB I/O, this commit makes the throughput with bfq grow by
    400%, from 25 to 100MB/s. This higher throughput is 10MB/s lower than
    that reached with none. As some less random I/O is added to the mix,
    the throughput becomes equal to or higher than that with none.
    
    This commit is a very first attempt to recover throughput without
    losing control, and certainly has many limitations. One is, e.g., that
    the processes whose service is injected are not chosen so as to
    distribute the extra bandwidth they receive in accordance to their
    weights. Thus there might be loss of weighted fairness in some
    cases. Anyway, this loss concerns extra service, which would not have
    been received at all without this commit. Other limitations and issues
    will probably show up with usage.
    
    Signed-off-by: Paolo Valente <paolo.valente@linaro.org>
    Signed-off-by: Jens Axboe <axboe@kernel.dk>

diff --git a/block/bfq-iosched.h b/block/bfq-iosched.h
index a8a2e5aca4d4..37d627afdc2e 100644
--- a/block/bfq-iosched.h
+++ b/block/bfq-iosched.h
@@ -351,6 +351,32 @@ struct bfq_queue {
 	unsigned long split_time; /* time of last split */
 
 	unsigned long first_IO_time; /* time of first I/O for this queue */
+
+	/* max service rate measured so far */
+	u32 max_service_rate;
+	/*
+	 * Ratio between the service received by bfqq while it is in
+	 * service, and the cumulative service (of requests of other
+	 * queues) that may be injected while bfqq is empty but still
+	 * in service. To increase precision, the coefficient is
+	 * measured in tenths of unit. Here are some example of (1)
+	 * ratios, (2) resulting percentages of service injected
+	 * w.r.t. to the total service dispatched while bfqq is in
+	 * service, and (3) corresponding values of the coefficient:
+	 * 1 (50%) -> 10
+	 * 2 (33%) -> 20
+	 * 10 (9%) -> 100
+	 * 9.9 (9%) -> 99
+	 * 1.5 (40%) -> 15
+	 * 0.5 (66%) -> 5
+	 * 0.1 (90%) -> 1
+	 *
+	 * So, if the coefficient is lower than 10, then
+	 * injected service is more than bfqq service.
+	 */
+	unsigned int inject_coeff;
+	/* amount of service injected in current service slot */
+	unsigned int injected_service;
 };
 
 /**