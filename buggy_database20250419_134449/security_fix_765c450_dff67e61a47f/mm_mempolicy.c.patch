commit 765c4507af71c39aba21006bbd3ec809fe9714ff
Author: Christoph Lameter <clameter@sgi.com>
Date:   Wed Sep 27 01:50:08 2006 -0700

    [PATCH] GFP_THISNODE for the slab allocator
    
    This patch insures that the slab node lists in the NUMA case only contain
    slabs that belong to that specific node.  All slab allocations use
    GFP_THISNODE when calling into the page allocator.  If an allocation fails
    then we fall back in the slab allocator according to the zonelists appropriate
    for a certain context.
    
    This allows a replication of the behavior of alloc_pages and alloc_pages node
    in the slab layer.
    
    Currently allocations requested from the page allocator may be redirected via
    cpusets to other nodes.  This results in remote pages on nodelists and that in
    turn results in interrupt latency issues during cache draining.  Plus the slab
    is handing out memory as local when it is really remote.
    
    Fallback for slab memory allocations will occur within the slab allocator and
    not in the page allocator.  This is necessary in order to be able to use the
    existing pools of objects on the nodes that we fall back to before adding more
    pages to a slab.
    
    The fallback function insures that the nodes we fall back to obey cpuset
    restrictions of the current context.  We do not allocate objects from outside
    of the current cpuset context like before.
    
    Note that the implementation of locality constraints within the slab allocator
    requires importing logic from the page allocator.  This is a mischmash that is
    not that great.  Other allocators (uncached allocator, vmalloc, huge pages)
    face similar problems and have similar minimal reimplementations of the basic
    fallback logic of the page allocator.  There is another way of implementing a
    slab by avoiding per node lists (see modular slab) but this wont work within
    the existing slab.
    
    V1->V2:
    - Use NUMA_BUILD to avoid #ifdef CONFIG_NUMA
    - Exploit GFP_THISNODE being 0 in the NON_NUMA case to avoid another
      #ifdef
    
    [akpm@osdl.org: build fix]
    Signed-off-by: Christoph Lameter <clameter@sgi.com>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/mm/mempolicy.c b/mm/mempolicy.c
index 38f89650bc84..cf18f0942553 100644
--- a/mm/mempolicy.c
+++ b/mm/mempolicy.c
@@ -1136,7 +1136,9 @@ static unsigned interleave_nodes(struct mempolicy *policy)
  */
 unsigned slab_node(struct mempolicy *policy)
 {
-	switch (policy->policy) {
+	int pol = policy ? policy->policy : MPOL_DEFAULT;
+
+	switch (pol) {
 	case MPOL_INTERLEAVE:
 		return interleave_nodes(policy);