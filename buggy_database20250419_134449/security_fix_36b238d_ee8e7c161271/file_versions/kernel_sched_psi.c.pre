commit b05e75d611380881e73edc58a20fd8c6bb71720b
Author: Johannes Weiner <hannes@cmpxchg.org>
Date:   Mon Mar 16 15:13:31 2020 -0400

    psi: Fix cpu.pressure for cpu.max and competing cgroups
    
    For simplicity, cpu pressure is defined as having more than one
    runnable task on a given CPU. This works on the system-level, but it
    has limitations in a cgrouped reality: When cpu.max is in use, it
    doesn't capture the time in which a task is not executing on the CPU
    due to throttling. Likewise, it doesn't capture the time in which a
    competing cgroup is occupying the CPU - meaning it only reflects
    cgroup-internal competitive pressure, not outside pressure.
    
    Enable tracking of currently executing tasks, and then change the
    definition of cpu pressure in a cgroup from
    
            NR_RUNNING > 1
    
    to
    
            NR_RUNNING > ON_CPU
    
    which will capture the effects of cpu.max as well as competition from
    outside the cgroup.
    
    After this patch, a cgroup running `stress -c 1` with a cpu.max
    setting of 5000 10000 shows ~50% continuous CPU pressure.
    
    Signed-off-by: Johannes Weiner <hannes@cmpxchg.org>
    Signed-off-by: Peter Zijlstra (Intel) <peterz@infradead.org>
    Link: https://lkml.kernel.org/r/20200316191333.115523-2-hannes@cmpxchg.org

diff --git a/kernel/sched/psi.c b/kernel/sched/psi.c
index 028520702717..50128297a4f9 100644
--- a/kernel/sched/psi.c
+++ b/kernel/sched/psi.c
@@ -225,7 +225,7 @@ static bool test_state(unsigned int *tasks, enum psi_states state)
 	case PSI_MEM_FULL:
 		return tasks[NR_MEMSTALL] && !tasks[NR_RUNNING];
 	case PSI_CPU_SOME:
-		return tasks[NR_RUNNING] > 1;
+		return tasks[NR_RUNNING] > tasks[NR_ONCPU];
 	case PSI_NONIDLE:
 		return tasks[NR_IOWAIT] || tasks[NR_MEMSTALL] ||
 			tasks[NR_RUNNING];
@@ -695,10 +695,10 @@ static u32 psi_group_change(struct psi_group *group, int cpu,
 		if (!(m & (1 << t)))
 			continue;
 		if (groupc->tasks[t] == 0 && !psi_bug) {
-			printk_deferred(KERN_ERR "psi: task underflow! cpu=%d t=%d tasks=[%u %u %u] clear=%x set=%x\n",
+			printk_deferred(KERN_ERR "psi: task underflow! cpu=%d t=%d tasks=[%u %u %u %u] clear=%x set=%x\n",
 					cpu, t, groupc->tasks[0],
 					groupc->tasks[1], groupc->tasks[2],
-					clear, set);
+					groupc->tasks[3], clear, set);
 			psi_bug = 1;
 		}
 		groupc->tasks[t]--;
@@ -916,9 +916,11 @@ void cgroup_move_task(struct task_struct *task, struct css_set *to)
 
 	rq = task_rq_lock(task, &rf);
 
-	if (task_on_rq_queued(task))
+	if (task_on_rq_queued(task)) {
 		task_flags = TSK_RUNNING;
-	else if (task->in_iowait)
+		if (task_current(rq, task))
+			task_flags |= TSK_ONCPU;
+	} else if (task->in_iowait)
 		task_flags = TSK_IOWAIT;
 
 	if (task->flags & PF_MEMSTALL)