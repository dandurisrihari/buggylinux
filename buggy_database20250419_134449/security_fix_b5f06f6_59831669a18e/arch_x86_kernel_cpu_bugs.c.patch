commit b5f06f64e269f9820cd5ad9e9a98afa6c8914b7a
Author: Balbir Singh <sblbir@amazon.com>
Date:   Mon Apr 26 21:42:30 2021 +0200

    x86/mm: Prepare for opt-in based L1D flush in switch_mm()
    
    The goal of this is to allow tasks that want to protect sensitive
    information, against e.g. the recently found snoop assisted data sampling
    vulnerabilites, to flush their L1D on being switched out.  This protects
    their data from being snooped or leaked via side channels after the task
    has context switched out.
    
    This could also be used to wipe L1D when an untrusted task is switched in,
    but that's not a really well defined scenario while the opt-in variant is
    clearly defined.
    
    The mechanism is default disabled and can be enabled on the kernel command
    line.
    
    Prepare for the actual prctl based opt-in:
    
      1) Provide the necessary setup functionality similar to the other
         mitigations and enable the static branch when the command line option
         is set and the CPU provides support for hardware assisted L1D
         flushing. Software based L1D flush is not supported because it's CPU
         model specific and not really well defined.
    
         This does not come with a sysfs file like the other mitigations
         because it is not bound to any specific vulnerability.
    
         Support has to be queried via the prctl(2) interface.
    
      2) Add TIF_SPEC_L1D_FLUSH next to L1D_SPEC_IB so the two bits can be
         mangled into the mm pointer in one go which allows to reuse the
         existing mechanism in switch_mm() for the conditional IBPB speculation
         barrier efficiently.
    
      3) Add the L1D flush specific functionality which flushes L1D when the
         outgoing task opted in.
    
         Also check whether the incoming task has requested L1D flush and if so
         validate that it is not accidentaly running on an SMT sibling as this
         makes the whole excercise moot because SMT siblings share L1D which
         opens tons of other attack vectors. If that happens schedule task work
         which signals the incoming task on return to user/guest with SIGBUS as
         this is part of the paranoid L1D flush contract.
    
    Suggested-by: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Balbir Singh <sblbir@amazon.com>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Link: https://lore.kernel.org/r/20210108121056.21940-1-sblbir@amazon.com

diff --git a/arch/x86/kernel/cpu/bugs.c b/arch/x86/kernel/cpu/bugs.c
index d41b70fe4918..1a5a1b085eaa 100644
--- a/arch/x86/kernel/cpu/bugs.c
+++ b/arch/x86/kernel/cpu/bugs.c
@@ -43,6 +43,7 @@ static void __init mds_select_mitigation(void);
 static void __init mds_print_mitigation(void);
 static void __init taa_select_mitigation(void);
 static void __init srbds_select_mitigation(void);
+static void __init l1d_flush_select_mitigation(void);
 
 /* The base value of the SPEC_CTRL MSR that always has to be preserved. */
 u64 x86_spec_ctrl_base;
@@ -76,6 +77,13 @@ EXPORT_SYMBOL_GPL(mds_user_clear);
 DEFINE_STATIC_KEY_FALSE(mds_idle_clear);
 EXPORT_SYMBOL_GPL(mds_idle_clear);
 
+/*
+ * Controls whether l1d flush based mitigations are enabled,
+ * based on hw features and admin setting via boot parameter
+ * defaults to false
+ */
+DEFINE_STATIC_KEY_FALSE(switch_mm_cond_l1d_flush);
+
 void __init check_bugs(void)
 {
 	identify_boot_cpu();
@@ -111,6 +119,7 @@ void __init check_bugs(void)
 	mds_select_mitigation();
 	taa_select_mitigation();
 	srbds_select_mitigation();
+	l1d_flush_select_mitigation();
 
 	/*
 	 * As MDS and TAA mitigations are inter-related, print MDS
@@ -491,6 +500,34 @@ static int __init srbds_parse_cmdline(char *str)
 }
 early_param("srbds", srbds_parse_cmdline);
 
+#undef pr_fmt
+#define pr_fmt(fmt)     "L1D Flush : " fmt
+
+enum l1d_flush_mitigations {
+	L1D_FLUSH_OFF = 0,
+	L1D_FLUSH_ON,
+};
+
+static enum l1d_flush_mitigations l1d_flush_mitigation __initdata = L1D_FLUSH_OFF;
+
+static void __init l1d_flush_select_mitigation(void)
+{
+	if (!l1d_flush_mitigation || !boot_cpu_has(X86_FEATURE_FLUSH_L1D))
+		return;
+
+	static_branch_enable(&switch_mm_cond_l1d_flush);
+	pr_info("Conditional flush on switch_mm() enabled\n");
+}
+
+static int __init l1d_flush_parse_cmdline(char *str)
+{
+	if (!strcmp(str, "on"))
+		l1d_flush_mitigation = L1D_FLUSH_ON;
+
+	return 0;
+}
+early_param("l1d_flush", l1d_flush_parse_cmdline);
+
 #undef pr_fmt
 #define pr_fmt(fmt)     "Spectre V1 : " fmt