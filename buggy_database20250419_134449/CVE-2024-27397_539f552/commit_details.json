{
  "hash": "539f552892b757ca7a9eb1ba34f5be3c0a947f59",
  "hash_short": "539f5528",
  "subject": "slab: Achieve better kmalloc caches randomization in kvmalloc",
  "body": "As revealed by this writeup[1], due to the fact that __kmalloc_node (now\nrenamed to __kmalloc_node_noprof) is an exported symbol and will never\nget inlined, using it in kvmalloc_node (now is __kvmalloc_node_noprof)\nwould make the RET_IP inside always point to the same address:\n\n    upper_caller\n        kvmalloc\n        kvmalloc_node\n        kvmalloc_node_noprof\n        __kvmalloc_node_noprof\t<-- all macros all the way down here\n            __kmalloc_node_noprof\n                __do_kmalloc_node(.., _RET_IP_)\n            ...\t\t\t<-- _RET_IP_ points to\n\nThat literally means all kmalloc invoked via kvmalloc would use the same\nseed for cache randomization (CONFIG_RANDOM_KMALLOC_CACHES), which makes\nthis hardening non-functional.\n\nThe root cause of this problem, IMHO, is that using RET_IP only cannot\nidentify the actual allocation site in case of kmalloc being called\ninside non-inlined wrappers or helper functions. And I believe there\ncould be similar cases in other functions. Nevertheless, I haven't\nthought of any good solution for this. So for now let's solve this\nspecific case first.\n\nFor __kvmalloc_node_noprof, replace __kmalloc_node_noprof and call\n__do_kmalloc_node directly instead, so that RET_IP can take the return\naddress of kvmalloc and differentiate each kvmalloc invocation:\n\n    upper_caller\n        kvmalloc\n        kvmalloc_node\n        kvmalloc_node_noprof\n        __kvmalloc_node_noprof\t<-- all macros all the way down here\n            __do_kmalloc_node(.., _RET_IP_)\n        ...\t\t\t<-- _RET_IP_ points to\n\nThanks to Tam\u00e1s Koczka for the report and discussion!\n\nLink: https://github.com/google/security-research/blob/908d59b573960dc0b90adda6f16f7017aca08609/pocs/linux/kernelctf/CVE-2024-27397_mitigation/docs/exploit.md?plain=1#L259 [1]\nReported-by: Tam\u00e1s Koczka <poprdi@google.com>\nSigned-off-by: GONG Ruiqi <gongruiqi1@huawei.com>\nReviewed-by: Hyeonggon Yoo <42.hyeyoo@gmail.com>\nTested-by: Hyeonggon Yoo <42.hyeyoo@gmail.com>\nSigned-off-by: Vlastimil Babka <vbabka@suse.cz>",
  "full_message": "slab: Achieve better kmalloc caches randomization in kvmalloc\n\nAs revealed by this writeup[1], due to the fact that __kmalloc_node (now\nrenamed to __kmalloc_node_noprof) is an exported symbol and will never\nget inlined, using it in kvmalloc_node (now is __kvmalloc_node_noprof)\nwould make the RET_IP inside always point to the same address:\n\n    upper_caller\n        kvmalloc\n        kvmalloc_node\n        kvmalloc_node_noprof\n        __kvmalloc_node_noprof\t<-- all macros all the way down here\n            __kmalloc_node_noprof\n                __do_kmalloc_node(.., _RET_IP_)\n            ...\t\t\t<-- _RET_IP_ points to\n\nThat literally means all kmalloc invoked via kvmalloc would use the same\nseed for cache randomization (CONFIG_RANDOM_KMALLOC_CACHES), which makes\nthis hardening non-functional.\n\nThe root cause of this problem, IMHO, is that using RET_IP only cannot\nidentify the actual allocation site in case of kmalloc being called\ninside non-inlined wrappers or helper functions. And I believe there\ncould be similar cases in other functions. Nevertheless, I haven't\nthought of any good solution for this. So for now let's solve this\nspecific case first.\n\nFor __kvmalloc_node_noprof, replace __kmalloc_node_noprof and call\n__do_kmalloc_node directly instead, so that RET_IP can take the return\naddress of kvmalloc and differentiate each kvmalloc invocation:\n\n    upper_caller\n        kvmalloc\n        kvmalloc_node\n        kvmalloc_node_noprof\n        __kvmalloc_node_noprof\t<-- all macros all the way down here\n            __do_kmalloc_node(.., _RET_IP_)\n        ...\t\t\t<-- _RET_IP_ points to\n\nThanks to Tam\u00e1s Koczka for the report and discussion!\n\nLink: https://github.com/google/security-research/blob/908d59b573960dc0b90adda6f16f7017aca08609/pocs/linux/kernelctf/CVE-2024-27397_mitigation/docs/exploit.md?plain=1#L259 [1]\nReported-by: Tam\u00e1s Koczka <poprdi@google.com>\nSigned-off-by: GONG Ruiqi <gongruiqi1@huawei.com>\nReviewed-by: Hyeonggon Yoo <42.hyeyoo@gmail.com>\nTested-by: Hyeonggon Yoo <42.hyeyoo@gmail.com>\nSigned-off-by: Vlastimil Babka <vbabka@suse.cz>",
  "author_name": "GONG Ruiqi",
  "author_email": "gongruiqi1@huawei.com",
  "author_date": "Wed Feb 12 16:15:05 2025 +0800",
  "author_date_iso": "2025-02-12T16:15:05+08:00",
  "committer_name": "Vlastimil Babka",
  "committer_email": "vbabka@suse.cz",
  "committer_date": "Tue Mar 4 08:53:50 2025 +0100",
  "committer_date_iso": "2025-03-04T08:53:50+01:00",
  "files_changed": [
    "mm/slub.c"
  ],
  "files_changed_count": 1,
  "stats": [
    {
      "file": "mm/slub.c",
      "insertions": 3,
      "deletions": 3
    }
  ],
  "total_insertions": 3,
  "total_deletions": 3,
  "total_changes": 6,
  "parents": [
    "f1157db8b539cf1a98678667255fa7efa1f5b2cb"
  ],
  "branches": [
    "* development",
    "remotes/origin/HEAD -> origin/master",
    "remotes/origin/master"
  ],
  "tags": [],
  "is_merge": false,
  "security_info": {
    "cve_ids": [
      "CVE-2024-27397"
    ],
    "security_keywords": [
      "hardening",
      "exploit"
    ]
  },
  "fix_type": "cve",
  "file_results": [
    {
      "file": "mm/slub.c",
      "pre_version": true,
      "post_version": true,
      "patch": true
    }
  ]
}